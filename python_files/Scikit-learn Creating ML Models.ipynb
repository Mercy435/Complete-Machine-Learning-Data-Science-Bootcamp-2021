{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn or scikit learn allows us build machine learning models.. it is built on numpy, matplotlib and python\n",
    "it has inbuilt ML models\n",
    "it has a very well designed API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a trained model is a ML model that has found patterns in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# introduction to scikit-learn (sklearn)\n",
    "\n",
    "## content\n",
    "an end-to-end Scikit-Learn workflow\n",
    "1. Getting the data ready\n",
    "2. choose the right estimator/algorithm for our problems\n",
    "3. fit the model/algorithm and use it to make predictions on our data\n",
    "4. evaluating the model\n",
    "5. improve a model\n",
    "6. save and load a trained model\n",
    "7. putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An end-to-end Scikit-Learn workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. get the data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "5     57    1   0       140   192    0        1      148      0      0.4   \n",
       "6     56    0   1       140   294    0        0      153      0      1.3   \n",
       "7     44    1   1       120   263    0        1      173      0      0.0   \n",
       "8     52    1   2       172   199    1        1      162      0      0.5   \n",
       "9     57    1   2       150   168    0        1      174      0      1.6   \n",
       "10    54    1   0       140   239    0        1      160      0      1.2   \n",
       "11    48    0   2       130   275    0        1      139      0      0.2   \n",
       "12    49    1   1       130   266    0        1      171      0      0.6   \n",
       "13    64    1   3       110   211    0        0      144      1      1.8   \n",
       "14    58    0   3       150   283    1        0      162      0      1.0   \n",
       "15    50    0   2       120   219    0        1      158      0      1.6   \n",
       "16    58    0   2       120   340    0        1      172      0      0.0   \n",
       "17    66    0   3       150   226    0        1      114      0      2.6   \n",
       "18    43    1   0       150   247    0        1      171      0      1.5   \n",
       "19    69    0   3       140   239    0        1      151      0      1.8   \n",
       "20    59    1   0       135   234    0        1      161      0      0.5   \n",
       "21    44    1   2       130   233    0        1      179      1      0.4   \n",
       "22    42    1   0       140   226    0        1      178      0      0.0   \n",
       "23    61    1   2       150   243    1        1      137      1      1.0   \n",
       "24    40    1   3       140   199    0        1      178      1      1.4   \n",
       "25    71    0   1       160   302    0        1      162      0      0.4   \n",
       "26    59    1   2       150   212    1        1      157      0      1.6   \n",
       "27    51    1   2       110   175    0        1      123      0      0.6   \n",
       "28    65    0   2       140   417    1        0      157      0      0.8   \n",
       "29    53    1   2       130   197    1        0      152      0      1.2   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "273   58    1   0       100   234    0        1      156      0      0.1   \n",
       "274   47    1   0       110   275    0        0      118      1      1.0   \n",
       "275   52    1   0       125   212    0        1      168      0      1.0   \n",
       "276   58    1   0       146   218    0        1      105      0      2.0   \n",
       "277   57    1   1       124   261    0        1      141      0      0.3   \n",
       "278   58    0   1       136   319    1        0      152      0      0.0   \n",
       "279   61    1   0       138   166    0        0      125      1      3.6   \n",
       "280   42    1   0       136   315    0        1      125      1      1.8   \n",
       "281   52    1   0       128   204    1        1      156      1      1.0   \n",
       "282   59    1   2       126   218    1        1      134      0      2.2   \n",
       "283   40    1   0       152   223    0        1      181      0      0.0   \n",
       "284   61    1   0       140   207    0        0      138      1      1.9   \n",
       "285   46    1   0       140   311    0        1      120      1      1.8   \n",
       "286   59    1   3       134   204    0        1      162      0      0.8   \n",
       "287   57    1   1       154   232    0        0      164      0      0.0   \n",
       "288   57    1   0       110   335    0        1      143      1      3.0   \n",
       "289   55    0   0       128   205    0        2      130      1      2.0   \n",
       "290   61    1   0       148   203    0        1      161      0      0.0   \n",
       "291   58    1   0       114   318    0        2      140      0      4.4   \n",
       "292   58    0   0       170   225    1        0      146      1      2.8   \n",
       "293   67    1   2       152   212    0        0      150      0      0.8   \n",
       "294   44    1   0       120   169    0        1      144      1      2.8   \n",
       "295   63    1   0       140   187    0        0      144      1      4.0   \n",
       "296   63    0   0       124   197    0        1      136      1      0.0   \n",
       "297   59    1   0       164   176    1        0       90      0      1.0   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "5        1   0     1       1  \n",
       "6        1   0     2       1  \n",
       "7        2   0     3       1  \n",
       "8        2   0     3       1  \n",
       "9        2   0     2       1  \n",
       "10       2   0     2       1  \n",
       "11       2   0     2       1  \n",
       "12       2   0     2       1  \n",
       "13       1   0     2       1  \n",
       "14       2   0     2       1  \n",
       "15       1   0     2       1  \n",
       "16       2   0     2       1  \n",
       "17       0   0     2       1  \n",
       "18       2   0     2       1  \n",
       "19       2   2     2       1  \n",
       "20       1   0     3       1  \n",
       "21       2   0     2       1  \n",
       "22       2   0     2       1  \n",
       "23       1   0     2       1  \n",
       "24       2   0     3       1  \n",
       "25       2   2     2       1  \n",
       "26       2   0     2       1  \n",
       "27       2   0     2       1  \n",
       "28       2   1     2       1  \n",
       "29       0   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "273      2   1     3       0  \n",
       "274      1   1     2       0  \n",
       "275      2   2     3       0  \n",
       "276      1   1     3       0  \n",
       "277      2   0     3       0  \n",
       "278      2   2     2       0  \n",
       "279      1   1     2       0  \n",
       "280      1   0     1       0  \n",
       "281      1   0     0       0  \n",
       "282      1   1     1       0  \n",
       "283      2   0     3       0  \n",
       "284      2   1     3       0  \n",
       "285      1   2     3       0  \n",
       "286      2   2     2       0  \n",
       "287      2   1     2       0  \n",
       "288      1   1     3       0  \n",
       "289      1   1     3       0  \n",
       "290      2   1     3       0  \n",
       "291      0   3     1       0  \n",
       "292      1   2     1       0  \n",
       "293      1   0     3       0  \n",
       "294      0   0     1       0  \n",
       "295      2   2     3       0  \n",
       "296      1   0     2       0  \n",
       "297      1   2     1       0  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "heart_disease=pd.read_csv(\"./csv_files/heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use all of the columns to predict target(1 or 0: heart-disease or not),, a classification problem\n",
    "\n",
    "# create X (features matrix)\n",
    "X=heart_disease.drop(\"target\", axis=1) # to drop the target column\n",
    "\n",
    "#create y(labels)\n",
    "y=heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. choose the right model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf= RandomForestClassifier() # set estimators at 100, default value\n",
    "# clf= RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# keep the default hyperparameters\n",
    "clf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# find the patterns in the training data\n",
    "\n",
    "clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-046f29cb2762>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make a prediction on arrays that look like the model we have trained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \"\"\"\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# make a prediction on arrays that look like the model we have trained\n",
    "y_label=clf.predict(np.array([0,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. evaluate the model on the training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_train, y_train) \n",
    "#1.0 rep 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)\n",
    "#77% accuaracy on test data cos it has never seen the data nor its labels.. it  gets 87 out of a 100 data right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. improve a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_\n",
    "# try a diff amount of n_estimators\n",
    "np.random.seed(42)\n",
    "for i in range(10,120,10):\n",
    "    print(f\"Trying model with {i} estimators.....\")\n",
    "    clf=RandomForestClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    print(f\"Model accuracy on test set: {clf.score(X_test, y_test) * 100:.2f}%\")\n",
    "    print(\"\")\n",
    "    \n",
    "#when n=100 here, we get 93.7\n",
    "#from the initial model, n=100,we got 77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. save and load a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle.dump(clf,open(\"random_forst_model_1.pkl\", \"wb\")) # to save model and createa  name for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model=pickle.load(open(\"random_forst_model_1.pkl\", \"rb\"))\n",
    "# np.random.seed(42)\n",
    "loaded_model.score(X_test,y_test)\n",
    " # this matches the last accuracy we got.. same accuracy as the recently trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debugging warnings in jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. do what the warning says\n",
    "2. import warnings\n",
    "   warnings. filterwarnings(\"ignore\")   for warnings u are sure wont affect ur code\n",
    "   warnings. filterwarnings(\"default\")  this brings the warning bk\n",
    "3. u can upgrade ur package to get rid of some warnings\n",
    "look up the dependencies and set version number of packages u want to install,, u can uninstall thise preventing the upgrade of a package then install the proper version format\n",
    "A Python script that reports warnings when it runs can be frustrating.\n",
    "\n",
    "For a beginner, it may feel like the code is not working correctly, that perhaps you have done something wrong.\n",
    "For a professional, it is a sign of a program that requires updating\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Revisiting End2END SCi-KIt learn flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GETTING DATA READY -splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting our data ready to be used with ML\n",
    "\n",
    "three main things to do\"\n",
    "1. split data into features and labels( X annd y)\n",
    "2. filling/imputing/disregarding missing values-- ml cant learn when there is no info,, it throws an error\n",
    "3. converting non numerical values to numerical values(also called feature coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "X=heart_disease.drop(\"target\", axis=1)\n",
    "# axis=0, is row axis, axis=1 is column axis\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "y= heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test set\n",
    "\n",
    "# note that it is a fundamemtal principle never to evaluate models on data it has learnt from , \n",
    "# hence we split into training and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "#13 rep the n of columns in x\n",
    "#242 is 80% of total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0] * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "242 + 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the more data we have , the more we have to work with but we need useful data\n",
    "clean data- transform data- reduce data\n",
    "we remove and replace data when cleaning data, due to missing values, missing labels cos we cant build an acurate model with these missing data\n",
    "\n",
    "transform data--\n",
    "computers only understand 1 and 0... convert info into numbers,, use same unit for data across board...  \n",
    "\n",
    "reduce data--\n",
    "big data causes money.. more cpus... data reduction is sometimes caled column/dimensionality reduction... remove irrelevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. make sure data is all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales=pd.read_csv(\"./csv_files/car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-96b04534a8e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcar_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_sales\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'car_sales' is not defined"
     ]
    }
   ],
   "source": [
    "car_sales.shape, len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b49867664667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcar_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'car_sales' is not defined"
     ]
    }
   ],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-893263568dac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#split into X,y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcar_sales\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Price\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcar_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Price\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# split into training and set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'car_sales' is not defined"
     ]
    }
   ],
   "source": [
    "#split into X,y\n",
    "X=car_sales.drop(\"Price\", axis=1)\n",
    "y=car_sales[\"Price\"]\n",
    "\n",
    "# split into training and set\n",
    "X_train, X_test, y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46018279569892473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor # this is same as classification but is used to predict a number(price of the car)\n",
    "\n",
    "model=RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the error above is because our data is not all numerical, look at the make and colour columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f26a753bad66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcar_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Doors'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#door is categorical as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'car_sales' is not defined"
     ]
    }
   ],
   "source": [
    "car_sales['Doors'].value_counts()  #door is categorical as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>417</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>319</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>126</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>152</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>176</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "5     57    1   0       140   192    0        1      148      0      0.4   \n",
       "6     56    0   1       140   294    0        0      153      0      1.3   \n",
       "7     44    1   1       120   263    0        1      173      0      0.0   \n",
       "8     52    1   2       172   199    1        1      162      0      0.5   \n",
       "9     57    1   2       150   168    0        1      174      0      1.6   \n",
       "10    54    1   0       140   239    0        1      160      0      1.2   \n",
       "11    48    0   2       130   275    0        1      139      0      0.2   \n",
       "12    49    1   1       130   266    0        1      171      0      0.6   \n",
       "13    64    1   3       110   211    0        0      144      1      1.8   \n",
       "14    58    0   3       150   283    1        0      162      0      1.0   \n",
       "15    50    0   2       120   219    0        1      158      0      1.6   \n",
       "16    58    0   2       120   340    0        1      172      0      0.0   \n",
       "17    66    0   3       150   226    0        1      114      0      2.6   \n",
       "18    43    1   0       150   247    0        1      171      0      1.5   \n",
       "19    69    0   3       140   239    0        1      151      0      1.8   \n",
       "20    59    1   0       135   234    0        1      161      0      0.5   \n",
       "21    44    1   2       130   233    0        1      179      1      0.4   \n",
       "22    42    1   0       140   226    0        1      178      0      0.0   \n",
       "23    61    1   2       150   243    1        1      137      1      1.0   \n",
       "24    40    1   3       140   199    0        1      178      1      1.4   \n",
       "25    71    0   1       160   302    0        1      162      0      0.4   \n",
       "26    59    1   2       150   212    1        1      157      0      1.6   \n",
       "27    51    1   2       110   175    0        1      123      0      0.6   \n",
       "28    65    0   2       140   417    1        0      157      0      0.8   \n",
       "29    53    1   2       130   197    1        0      152      0      1.2   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "273   58    1   0       100   234    0        1      156      0      0.1   \n",
       "274   47    1   0       110   275    0        0      118      1      1.0   \n",
       "275   52    1   0       125   212    0        1      168      0      1.0   \n",
       "276   58    1   0       146   218    0        1      105      0      2.0   \n",
       "277   57    1   1       124   261    0        1      141      0      0.3   \n",
       "278   58    0   1       136   319    1        0      152      0      0.0   \n",
       "279   61    1   0       138   166    0        0      125      1      3.6   \n",
       "280   42    1   0       136   315    0        1      125      1      1.8   \n",
       "281   52    1   0       128   204    1        1      156      1      1.0   \n",
       "282   59    1   2       126   218    1        1      134      0      2.2   \n",
       "283   40    1   0       152   223    0        1      181      0      0.0   \n",
       "284   61    1   0       140   207    0        0      138      1      1.9   \n",
       "285   46    1   0       140   311    0        1      120      1      1.8   \n",
       "286   59    1   3       134   204    0        1      162      0      0.8   \n",
       "287   57    1   1       154   232    0        0      164      0      0.0   \n",
       "288   57    1   0       110   335    0        1      143      1      3.0   \n",
       "289   55    0   0       128   205    0        2      130      1      2.0   \n",
       "290   61    1   0       148   203    0        1      161      0      0.0   \n",
       "291   58    1   0       114   318    0        2      140      0      4.4   \n",
       "292   58    0   0       170   225    1        0      146      1      2.8   \n",
       "293   67    1   2       152   212    0        0      150      0      0.8   \n",
       "294   44    1   0       120   169    0        1      144      1      2.8   \n",
       "295   63    1   0       140   187    0        0      144      1      4.0   \n",
       "296   63    0   0       124   197    0        1      136      1      0.0   \n",
       "297   59    1   0       164   176    1        0       90      0      1.0   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "0        0   0     1  \n",
       "1        0   0     2  \n",
       "2        2   0     2  \n",
       "3        2   0     2  \n",
       "4        2   0     2  \n",
       "5        1   0     1  \n",
       "6        1   0     2  \n",
       "7        2   0     3  \n",
       "8        2   0     3  \n",
       "9        2   0     2  \n",
       "10       2   0     2  \n",
       "11       2   0     2  \n",
       "12       2   0     2  \n",
       "13       1   0     2  \n",
       "14       2   0     2  \n",
       "15       1   0     2  \n",
       "16       2   0     2  \n",
       "17       0   0     2  \n",
       "18       2   0     2  \n",
       "19       2   2     2  \n",
       "20       1   0     3  \n",
       "21       2   0     2  \n",
       "22       2   0     2  \n",
       "23       1   0     2  \n",
       "24       2   0     3  \n",
       "25       2   2     2  \n",
       "26       2   0     2  \n",
       "27       2   0     2  \n",
       "28       2   1     2  \n",
       "29       0   0     2  \n",
       "..     ...  ..   ...  \n",
       "273      2   1     3  \n",
       "274      1   1     2  \n",
       "275      2   2     3  \n",
       "276      1   1     3  \n",
       "277      2   0     3  \n",
       "278      2   2     2  \n",
       "279      1   1     2  \n",
       "280      1   0     1  \n",
       "281      1   0     0  \n",
       "282      1   1     1  \n",
       "283      2   0     3  \n",
       "284      2   1     3  \n",
       "285      1   2     3  \n",
       "286      2   2     2  \n",
       "287      2   1     2  \n",
       "288      1   1     3  \n",
       "289      1   1     3  \n",
       "290      2   1     3  \n",
       "291      0   3     1  \n",
       "292      1   2     1  \n",
       "293      1   0     3  \n",
       "294      0   0     1  \n",
       "295      2   2     3  \n",
       "296      1   0     2  \n",
       "297      1   2     1  \n",
       "298      1   0     3  \n",
       "299      1   0     3  \n",
       "300      1   2     3  \n",
       "301      1   1     3  \n",
       "302      1   1     2  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Make' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-94264caf8527>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# this take the onehotencoder and apply it to the cat fetaures and passthrough the remainder of the columns, dont do anything to it(in this case the odometer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtransformed_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtransformed_X\u001b[0m \u001b[1;31m# X now in numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_validate_remainder\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[0mcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_get_column_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[0mremaining_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         raise ValueError(\"No valid specification of the columns. Only a \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mall_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         raise ValueError(\"No valid specification of the columns. Only a \"\n",
      "\u001b[1;31mValueError\u001b[0m: 'Make' is not in list"
     ]
    }
   ],
   "source": [
    "# to make columns make and color numerical\n",
    "# turn caategories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features=[\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "# this turns categories into numbers\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "# this take the onehotencoder and apply it to the cat fetaures and passthrough the remainder of the columns, dont do anything to it(in this case the odometer)\n",
    "\n",
    "transformed_X=transformer.fit_transform(X)\n",
    "transformed_X # X now in numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformed_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ebc0c1a82ec3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# 12 rep the odometer column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformed_X' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(transformed_X)\n",
    "# 12 rep the odometer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1d2333608f3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# one hot encoding can be done in an alt way from pandas thus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdummies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_sales\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Make\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Colour\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Doors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdummies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#since doors is already numerical, it didnt work on it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'car_sales' is not defined"
     ]
    }
   ],
   "source": [
    "# one hot encoding can be done in an alt way from pandas thus\n",
    "dummies=pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies\n",
    "#since doors is already numerical, it didnt work on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformed_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-24a6a26d4b1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#splitting to train and test using transformed x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformed_X' is not defined"
     ]
    }
   ],
   "source": [
    "# now that all our data are in zeroos and ones, lets refit the models\n",
    "\n",
    "np.random.seed(42)\n",
    "#splitting to train and test using transformed x\n",
    "X_train, X_test, y_train, y_test=train_test_split(transformed_X,y, test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46018279569892473"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 dealing with missing data \n",
    "\n",
    "1. fill them with some value(imputation)\n",
    "2. remove the samples with missing data altogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import car sales missing data\n",
    "car_sales_missing=pd.read_csv(\"./csv_files/car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the total number of empty cells in a column\n",
    "\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and y\n",
    "\n",
    "X=car_sales_missing.drop(\"Price\", axis=1)\n",
    "y=car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-9a0e2a772db8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"one_hot\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremainder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtransformed_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mtransformed_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fit_transform_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[0;32m    410\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m    411\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[1;32m--> 412\u001b[1;33m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 self._categorical_features, copy=True)\n\u001b[0;32m    630\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_legacy_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_idx_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_drop_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mX_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_categories\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mXi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             Xi = check_array(Xi, ensure_2d=False, dtype=None,\n\u001b[1;32m---> 67\u001b[1;33m                              force_all_finite=needs_validation)\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[0mX_columns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "# lets try and convert data to numbers\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features=[\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "transformed_X=transformer.fit_transform(X)\n",
    "transformed_X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it returns an error cos of the nan values present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>42652.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163453.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>130538.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>51029.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>167421.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Green</td>\n",
       "      <td>17119.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>102303.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>134181.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>199833.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>205592.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>96742.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BMW</td>\n",
       "      <td>White</td>\n",
       "      <td>194189.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>67991.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>215820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124844.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Honda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30615.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>148744.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>130075.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>172718.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>125819.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>180390.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>82783.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>56687.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>112004.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>186309.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Black</td>\n",
       "      <td>178164.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>237627.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155383.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Honda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22409.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>95317.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>128016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>BMW</td>\n",
       "      <td>White</td>\n",
       "      <td>85739.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>17975.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>230314.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>129454.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>238172.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>157235.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Blue</td>\n",
       "      <td>216250.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>71934.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215235.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Black</td>\n",
       "      <td>248736.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>41735.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>173408.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>235985.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>54721.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Black</td>\n",
       "      <td>162523.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163322.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "5     Honda    Red        42652.0    4.0  23883.0\n",
       "6    Toyota   Blue       163453.0    4.0   8473.0\n",
       "7     Honda  White            NaN    4.0  20306.0\n",
       "8       NaN  White       130538.0    4.0   9374.0\n",
       "9     Honda   Blue        51029.0    4.0  26683.0\n",
       "10   Nissan  White       167421.0    4.0  16259.0\n",
       "11   Nissan  Green        17119.0    4.0   6160.0\n",
       "12   Nissan  White       102303.0    4.0  16909.0\n",
       "13      NaN  White       134181.0    4.0  11121.0\n",
       "14    Honda   Blue       199833.0    4.0  18946.0\n",
       "15   Toyota   Blue       205592.0    4.0  16290.0\n",
       "16   Toyota    Red        96742.0    4.0  34465.0\n",
       "17      BMW  White       194189.0    5.0  17177.0\n",
       "18   Nissan  White        67991.0    3.0   9109.0\n",
       "19   Nissan   Blue       215820.0    4.0   6010.0\n",
       "20   Toyota    NaN       124844.0    4.0  24130.0\n",
       "21    Honda    NaN        30615.0    4.0  29653.0\n",
       "22   Toyota  White       148744.0    4.0  22489.0\n",
       "23    Honda  Green       130075.0    4.0  21242.0\n",
       "24    Honda   Blue       172718.0    4.0  14274.0\n",
       "25    Honda   Blue       125819.0    4.0  15686.0\n",
       "26    Honda  White       180390.0    4.0  13344.0\n",
       "27    Honda  Green        82783.0    4.0  10984.0\n",
       "28    Honda  White        56687.0    4.0   6135.0\n",
       "29   Toyota  White       112004.0    4.0  13586.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "970  Toyota   Blue       186309.0    4.0  16416.0\n",
       "971     BMW  Black       178164.0    3.0  24891.0\n",
       "972   Honda  White            NaN    4.0  17939.0\n",
       "973   Honda  Green       237627.0    4.0   8430.0\n",
       "974     NaN  White       155383.0    4.0  14345.0\n",
       "975   Honda    NaN        22409.0    4.0  10429.0\n",
       "976  Toyota   Blue        95317.0    4.0   7435.0\n",
       "977  Toyota   Blue       128016.0    4.0  16835.0\n",
       "978     BMW  White        85739.0    5.0  48419.0\n",
       "979  Toyota  Black        17975.0    4.0  17940.0\n",
       "980  Toyota   Blue       230314.0    4.0   6720.0\n",
       "981  Toyota  White       129454.0    4.0   6446.0\n",
       "982   Honda  White       238172.0    4.0  13273.0\n",
       "983  Toyota    Red            NaN    4.0  14671.0\n",
       "984  Nissan   Blue       157235.0    4.0   4196.0\n",
       "985     NaN   Blue       216250.0    4.0   9691.0\n",
       "986   Honda  White        71934.0    4.0  26882.0\n",
       "987   Honda  White       215235.0    4.0   3825.0\n",
       "988  Nissan  Black       248736.0    4.0   8358.0\n",
       "989  Toyota    Red        41735.0    4.0  13928.0\n",
       "990  Toyota  White       173408.0    4.0   8082.0\n",
       "991   Honda   Blue       235985.0    4.0   9184.0\n",
       "992   Honda  Green        54721.0    4.0  27419.0\n",
       "993  Nissan  Black       162523.0    4.0   4696.0\n",
       "994     BMW   Blue       163322.0    3.0  31666.0\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### option1. fill missing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    811\n",
       "5.0     75\n",
       "3.0     64\n",
       "Name: Doors, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#1.numerical columns can be filled with mean\n",
    "#2. categorical data can be filled with missing\n",
    "\n",
    "# fill the \"make\" colum\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace = True)\n",
    "\n",
    "# fill the \"Colour\" colum\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace = True)\n",
    "\n",
    "# fill the \"odometer\" colum\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace = True)\n",
    "\n",
    "# fill the \"doors\" colum\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              0\n",
       "Colour            0\n",
       "Odometer (KM)     0\n",
       "Doors             0\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing Price value\n",
    "\n",
    "car_sales_missing.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Odometer (KM)    0\n",
       "Doors            0\n",
       "Price            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car_sales_missing) # we have lost 50 of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=car_sales_missing.drop(\"Price\", axis=1)\n",
    "y=car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        3.54310e+04, 1.53230e+04],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, ..., 1.00000e+00,\n",
       "        1.92714e+05, 1.99430e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        8.47140e+04, 2.83430e+04],\n",
       "       ...,\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, ..., 0.00000e+00,\n",
       "        6.66040e+04, 3.15700e+04],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.15883e+05, 4.00100e+03],\n",
       "       [0.00000e+00, 0.00000e+00, 0.00000e+00, ..., 0.00000e+00,\n",
       "        2.48360e+05, 1.27320e+04]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features=[\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "transformed_X=transformer.fit_transform(X)\n",
    "transformed_X=transformer.fit_transform(car_sales_missing)\n",
    "transformed_X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPtion 2: fill missing values with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_missing_data=pd.read_csv(\"./csv_files/car-sales-extended-missing-data.csv\")\n",
    "car_missing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows with no labels(y)\n",
    "# drop rows that do not have price data, cos we dont want missing values in our label(y)\n",
    "car_missing_data.dropna(subset=[\"Price\"], inplace=True)\n",
    "car_missing_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X(features) and y(labels)\n",
    "X= car_missing_data.drop(\"Price\", axis = 1)\n",
    "\n",
    "y=car_missing_data[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Honda', 'White', 4.0, 35431.0],\n",
       "       ['BMW', 'Blue', 5.0, 192714.0],\n",
       "       ['Honda', 'White', 4.0, 84714.0],\n",
       "       ...,\n",
       "       ['Nissan', 'Blue', 4.0, 66604.0],\n",
       "       ['Honda', 'White', 4.0, 215883.0],\n",
       "       ['Toyota', 'Blue', 4.0, 248360.0]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill missing values with Scikit-learn(imputation)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#fill cat values with missing and num values with mean\n",
    "cat_imputer=SimpleImputer(strategy=\"constant\", fill_value=\"missing\")\n",
    "#this is used for inputing\n",
    "door_imputer=SimpleImputer(strategy=\"constant\", fill_value=4)\n",
    "num_imputer=SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "#define columns\n",
    "cat_features=[\"Make\", \"Colour\"]\n",
    "door_features=[\"Doors\"]\n",
    "#this is kinda half way number and half way category\n",
    "num_features=[\"Odometer (KM)\"]\n",
    "\n",
    "#create an imputer-sth that fills missing data\n",
    "imputer=ColumnTransformer([(\"cat_imputer\", cat_imputer, cat_features),\n",
    "                            (\"door_imputer\", door_imputer, door_features),\n",
    "                             (\"num_imputer\", num_imputer, num_features)])\n",
    "\n",
    "#Transform the data\n",
    "filled_X=imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             0\n",
       "Colour           0\n",
       "Doors            0\n",
       "Odometer (KM)    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X, columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<950x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting to numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features=[\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "transformer = ColumnTransformer([(\"one_hot\", one_hot, categorical_features)], remainder=\"passthrough\")\n",
    "\n",
    "transformed_X=transformer.fit_transform(car_sales_filled)\n",
    "transformed_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21990196728583944"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now that all our data as numbers and filled,(no missing data)\n",
    "\n",
    "#lets fit a model\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(transformed_X,\n",
    "                                                   y,\n",
    "                                                   test_size=0.2)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'car_sales' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-47da459ea954>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_sales_filled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_sales\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'car_sales' is not defined"
     ]
    }
   ],
   "source": [
    "len(car_sales_filled), len(car_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering or feature encoding is the process of turning nan to numerical values\n",
    "# imputation is the process of filling missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2. CHOOSING THE RIGHT ESTIMATOR/ALGORITHM FOR OUR PROGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "estimator=algorithm=model\n",
    "before choosing a model, det what kind of problem are u working with\n",
    "\n",
    "1.Classification-predicting whether a sample is one thing or another\n",
    "2. regression-predicting a number\n",
    "\n",
    "Often the hardest part of solving a machine learning problem can be finding the right estimator for the job.\n",
    "\n",
    "Different estimators are better suited for different types of data and different problems.\n",
    "\n",
    "step 1: check the scikit learn machine learning map\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ml_map.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Picking a machine learning model for a regression problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Boston housing dataset\n",
    "from sklearn.datasets import load_boston\n",
    "boston=load_boston()\n",
    "boston;\n",
    "# it loads as a dict with keys data, target, feature_names\n",
    "# this is a regression problem cos of the target(we need numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#always try to turn any dataset to a pandas dataframe\n",
    "boston_df = pd.DataFrame(boston[\"data\"], columns=boston[\"feature_names\"])\n",
    "boston_df[\"target\"]= pd.Series(boston[\"target\"])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the no of samples\n",
    "len(boston_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168519"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folow the map to det which model u will use.... we get to ridge regression\n",
    "\n",
    "#RIDGE REGRESSION\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "#set up a random seeed to make sure the results are reproducible\n",
    "np.random.seed(42)\n",
    "\n",
    "#create the data\n",
    "X=boston_df.drop(\"target\", axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "#split into train and test set\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#instanciate ridge model\n",
    "model=Ridge()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#check the score of the ridge model on test data\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we improve this score?\n",
    "### what if rdge wasnt working?\n",
    "### refer back to the map\n",
    " https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873969014117403"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble methods combine the predictions of several base estimators built with  a given learning algorithm to give robustness( combines smaler models to get its own predictions)\n",
    "#randomforest is an ensmeble method.. it has randomforstclassification and randomforstregression\n",
    "\n",
    "# imporving the model.. lets try randomforest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#create the data\n",
    "X=boston_df.drop(\"target\", axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "#split into train and test data\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# instantiate randomforestregressor\n",
    "rf=RandomForestRegressor(n_estimators=100) #it randomly create models when u run it\n",
    "\n",
    "#fit the model\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#test the model.. evaluate the randomforest regressor\n",
    "rf.score(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168519"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the ridge model \n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2.2 choosing an estimator for a classification problem\n",
    "lets go to the map\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ml_map.png\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a decision tree tells the machine to produce an if else statement for prediction\n",
    "heart_disease=pd.read_csv(\"./csv_files/heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4918032786885246"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we are predicting a category,,,, heart disease or no heart disease\n",
    "# following the map we get to linear svc\n",
    "\n",
    "# import the linearsvc estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#make the data'\n",
    "X= heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "#split the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# instantiate LinearSVC\n",
    "# clf=LinearSVC() # doing this alone gives a convergencewarning place the curosr in the bracket and do a shift tab to see the max iter=1000\n",
    "clf=LinearSVC(max_iter=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#evaluate LINEARSVC\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease[\"target\"].value_counts() #this is a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# go back to the map and see which u can use to get a better score\n",
    "#import randomforestcalssifeirr\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#make the data'\n",
    "X= heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "#split the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# instantiate RandomForestClassifier\n",
    "# clf=RandomForestClassifier()\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#evaluate RandomForestClassifier\n",
    "clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIDBIT:\n",
    "1. if you have structured data, use ensemble methods(randomforest ).. it's robust and can find patterns easily\n",
    "2. if u have unstructured data use deep learning or transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. FIT THE MODEL/ALGORITHM AND USE IT TO MAKE PREDICTIONS ON OUR DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 FITTING THE MODEL TO THE DATA\n",
    "\n",
    "Different names for:\n",
    "* X=features, features variables,data\n",
    "* y=labels,targets,target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#make the data'\n",
    "X= heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "#split the data\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# instantiate RandomForestClassifier\n",
    "# clf=RandomForestClassifier()\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fit the model to the data(training the machine learning model)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#evaluate RandomForestClassifier (testing or when the model is in production, it uses the pattern the model has learnt)\n",
    "clf.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we fit X and y, the model goes thru all of the examples in our training data, X and \n",
    "their corresponsing y values and finds the pattern.. and this varies for models\n",
    "\n",
    "the crux of ml models----mL MODELS figure out how patterns in a data fit to a label\n",
    "#training is another term for fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. MAKE PREDICTIONS USING A MACHINE LEARNING MODEL\n",
    "\n",
    "DURING TESTING, MODEL TEST DATA IT HAS NOT SEEN BEFORE(X_TEST) AND GETS Y_PREDS WHICH IT COMPARES WITH Y_TEST\n",
    "\n",
    "2 WAYS TO MAKE PREDICTIONS:\n",
    "    1. predict()\n",
    "    2. predict_proba()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predictions on classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 7. 8. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-7aa48156478c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# use a trained model to make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# this doesnt work... cos given data is not same as the trained data for the mdel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \"\"\"\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 7. 8. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# use a trained model to make predictions\n",
    "clf.predict(np.array([1,7,8,3,4])) # this doesnt work... cos given data is not same as the trained data for the mdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare predictions to truth labels to evaluate the label\n",
    "y_preds=clf.predict(X_test)\n",
    "np.mean(y_preds==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_preds, y_test)  #y_test is the y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions with 'predict_proba()'\n",
    " this give probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba() returns probabilities of a classification  model\n",
    "clf.predict_proba(X_test[:5])\n",
    "\n",
    "# coparing this code and that below,, if the value on the left is bigger, its a 0,,, if the value on the righ is bigger its a 1..\n",
    "# this instead of returning the value of the label,, it returns the prob of that value being true\n",
    "\n",
    "# the second output is less likely to be 1, model is unsure of it\n",
    "# but the model is very confident ot the first and fourth test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictig on the same data\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "179   57    1   0       150   276    0        0      112      1      0.6   \n",
       "228   59    1   3       170   288    0        0      159      0      0.2   \n",
       "111   57    1   2       150   126    1        1      173      0      0.2   \n",
       "246   56    0   0       134   409    0        0      150      1      1.9   \n",
       "60    71    0   2       110   265    1        0      130      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "179      1   1     1  \n",
       "228      1   0     3  \n",
       "111      2   1     3  \n",
       "246      1   2     3  \n",
       "60       2   1     2  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict() on regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#create the data\n",
    "X=boston_df.drop(\"target\", axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "#split into train and test set\n",
    "X_train,X_test, y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# instantiate and fit model\n",
    "model=RandomForestRegressor(n_estimators=100).fit(X_train,y_train)\n",
    "\n",
    "#make predictions\n",
    "y_preds=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.002, 30.826, 16.734, 23.467, 16.853, 21.725, 19.232, 15.239,\n",
       "       21.067, 20.738])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173    23.6\n",
       "274    32.4\n",
       "491    13.6\n",
       "72     22.8\n",
       "452    16.1\n",
       "76     20.0\n",
       "316    17.8\n",
       "140    14.0\n",
       "471    19.6\n",
       "500    16.8\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.6, 32.4, 13.6, 22.8, 16.1, 20. , 17.8, 14. , 19.6, 16.8])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1226372549019623"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare the predictions to the truth.. (compare how y_pred differs from y_test, cal the diff and do the average)\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output above is the diff on an average on how y_preds differ from y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluating a model - is the model working, can we use it to make predictions\n",
    "\n",
    "### 3 diff API for evaluating the quality of a model\n",
    "\n",
    "1. Estimator score method\n",
    "2. the scoring parameter\n",
    "3. problem specific metric functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1Evaluating  a method with Estimator score method-- this is a default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X=heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,y_train) # this returns mean accuracy for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test) # guessing would give 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be skeptical about any model that give 100%, no model is perfect.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do the same for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#create the data\n",
    "X=boston_df.drop(\"target\", axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "#split into train and test set\n",
    "X_train,X_test, y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# instantiate and fit model\n",
    "model=RandomForestRegressor(n_estimators=100).fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873969014117403"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)  # this returns the coefficient of determination, R^2 of the prediction.. this is for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Evaluating a  model using the scoring parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X=heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "clf.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/5-fold cross validation.jpeg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90322581, 0.80645161, 0.87096774, 0.87096774, 0.87096774,\n",
       "       0.8       , 0.76666667, 0.86666667, 0.72413793, 0.82758621])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_val_score(clf,X,y) # this returns an array, it evaluates a score by cross validation, this gives a warning\n",
    "cross_val_score(clf,X,y,cv=10) # cv can be an arbitrary no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation does 5 diff split.. it trains 5 diff versions of the model and \n",
    "# evaluates them on 5 diff versions of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8248087431693989)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "#single training and test split score\n",
    "clf_single_score=clf.score(X_test,y_test)\n",
    "\n",
    "#take the mean of the 5-fold cross-validation score\n",
    "clf_cross_val_score=np.mean(cross_val_score(clf,X,y,cv=5))\n",
    "\n",
    "#compare the two\n",
    "clf_single_score,clf_cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default scoring parameter for classifier is the mean accuracy\n",
    "#clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78688525, 0.86885246, 0.80327869, 0.78333333, 0.76666667])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the cross val score is more accurate than the single score\n",
    "\n",
    "# Scoring parameter set to None by default\n",
    "cross_val_score(clf,X,y,cv=5,scoring=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the scoring parameter can be changed,, we can determine what it should be "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Classification model evaluation metrics\n",
    "        1. accuracy\n",
    "        2. area under ROC curve\n",
    "        3. confusion matrix\n",
    "        4. classification report\n",
    "        \n",
    " ### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X=heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2) # this line is not needed cos it cross val\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "cross_val_score= cross_val_score(clf,X,y,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248087431693989"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Cross-Validated accuracy:82.48%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Heart Disease Classifier Cross-Validated accuracy:{np.mean(cross_val_score)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area Under receiving operating characteristic Curve (AUC/ROC)\n",
    " ````Area under curve(AUC)\n",
    "     ROC curve\n",
    "     \n",
    "ROc Curves are a comparison of a models true positive rate(tpr) versus a models false positive rate(fpr)\n",
    "\n",
    "True positive =model predicts 1 when truth is 1\n",
    "\n",
    "false positive = model predicts 1 when truth is 0\n",
    "\n",
    "True negative=model predict 0 when truth is 0\n",
    "\n",
    "false negative=model predicts 0 when truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X_test....etc\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.94, 0.06],\n",
       "        [0.42, 0.58],\n",
       "        [0.16, 0.84],\n",
       "        [0.5 , 0.5 ],\n",
       "        [0.25, 0.75],\n",
       "        [0.24, 0.76],\n",
       "        [0.32, 0.68],\n",
       "        [0.07, 0.93],\n",
       "        [0.99, 0.01],\n",
       "        [0.  , 1.  ]]), 61)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#fit the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#make predictions with probabilities\n",
    "y_probs=clf.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10],len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06, 0.58, 0.84, 0.5 , 0.75, 0.76, 0.68, 0.93, 0.01, 1.  ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_positive=y_probs[:, 1]\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.04, 0.04, 0.08, 0.12, 0.12,\n",
       "       0.12, 0.12, 0.6 , 0.64, 0.76, 0.88, 0.96, 1.  ])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate fpr,tpr and thresholds\n",
    "fpr,tpr,thresholds=roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a function for plotting ROC Curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr,tpr):\n",
    "    \"\"\"\n",
    "    Plots a ROC curve given the false positive rate(fpr)\n",
    "    and true positive rate(tpr) of a model.\n",
    "    \"\"\"\n",
    "    #plot roc curve\n",
    "    plt.plot(fpr, tpr, color=\"orange\", label=\"ROC\")\n",
    "\n",
    "    #plot line with no predictive power(baseline)\n",
    "    plt.plot([0,1],[0,1], color=\"darkblue\", linestyle=\"--\", label=\"Guessing\")\n",
    "\n",
    "    #customize the plot\n",
    "    plt.xlabel(\"False positive rate(fpr)\")\n",
    "    plt.ylabel(\"True positive rate(tpr)\")\n",
    "    plt.title(\"Receiver operating characteristic (ROC) curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9444444444444445"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot perfect roc curve and auc score\n",
    "fpr,tpr,tthresholds=roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ;erfect auc_curve\n",
    "roc_auc_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "a quick way to compare the labels a model predicts and the actual labels it was supposed to predict\n",
    "\n",
    "it gives an idea of where the model is getting confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22,  3],\n",
       "       [ 5, 31]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds=clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test,y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted labels   0   1\n",
       "Actual labels           \n",
       "0                 22   3\n",
       "1                  5  31"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize confusion matric with pd.crosstab()\n",
    "pd.crosstab(y_test,\n",
    "            y_preds,\n",
    "            rownames=[\"Actual labels\"],\n",
    "            colnames=[\"Predicted labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24+5+4+28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 61)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the left diagonals are the correct predictions, while the right diaginals are wrong(false negatives and false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "failed to create process.\n",
      "Access is denied.\n",
      "Access is denied.\n",
      "The system cannot find the file Alexander\\AppData\\Local\\Temp\\conda-23945-13952.tmp.\n",
      "Could Not Find C:\\Users\\Isaac Alexander\\AppData\\Local\\Temp\\conda-23945-13952.tmp\n",
      "'\"Ã¿Ã¾\"' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "Could Not Find C:\\Users\\Isaac Alexander\\PycharmProjects\\example1\\Complete-Machine-Learning-Data-Science-Bootcamp-2021\\Ã¿Ã¾\n"
     ]
    }
   ],
   "source": [
    "# for module not found error, install it thus:\n",
    "# how to install a conda package from jupyter nitebook into the current environ\n",
    "import sys # access the system\n",
    "!conda install --yes --prefix(sys.prefix) seaborn  # run  a bash command, prefic is another name for path name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24f9aefa860>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make our confusion matric more viible with seaborn heatmap\n",
    "import seaborn as sns\n",
    "\n",
    "#set the font scale\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "#create a confusion matrix\n",
    "conf_mat=confusion_matrix(y_test,y_preds)\n",
    "\n",
    "#plot it using seaborn\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    Plots a confusion matix using seaborn's heatmap()\n",
    "    \"\"\"\n",
    "    fig, ax=plt.subplots(figsize=(3,3))\n",
    "    ax=sns.heatmap(conf_mat,\n",
    "                   annot=True, #annotate the boxes with conf_mat info\n",
    "                    cbar=False)\n",
    "    plt.xlabel(\"True label\")\n",
    "    plt.ylabel(\"predicted label\")\n",
    "\n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "\n",
    " a collection of diff evaluation matrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85        25\n",
      "           1       0.91      0.86      0.89        36\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.86      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision is the proportion of positive identifications i.e.model predicted class 1.... a model which produces no false negatives has a precision of 1\n",
    "# recall is the proportion of actual postives which were corrected classified..... a model with no false negatives has a recall of 1\n",
    "# f1-score- combination of precision and recall... a perfect model receives and f1-score of 1.0\n",
    "# support- the no of samples each metric was calculated on\n",
    "#accuracy is in decimal --1.0\n",
    "#maro avg- avg precision,recall and f1-scores btw classes... it doesnt take class imbalance into acct\n",
    "# class imbalance -- relatively balanced btw 0 and 1\n",
    "# weighted avg-- avg weight of precision, recall and f1-score.... it is calculated wrt how many sample are in each class.. favours majority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# where precision and recall become valuable\n",
    "disease_true=np.zeros(10000)\n",
    "disease_true[0]=1 # only one positive case\n",
    "\n",
    "disease_preds=np.zeros(10000) #model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                    disease_preds,\n",
    "                                    output_dict=True))\n",
    "\n",
    "# using accuracy will be wrong .. look at other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of classification metrics:\n",
    "    ACCURACY- its a good measure to start with if all classes are balanced(e.g same amt of samples labelled 0 and 1)\n",
    "    PRECISION and RECALL are important when clasees are imbalanced\n",
    "    if false poitive predictions are worse than false negatives, aim for higher precision\n",
    "    if false negative predictions are worse than false positives, aim for higher recall\n",
    "    F1-SCORE combines recall and precision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. REGRESSION MODEL EVALUATION METRICS\n",
    "\n",
    "Model evaluation metrics documentation \n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "1. R^2 (coefficient of determination)\n",
    "2. MAE (mean acuurate error)\n",
    "3. MSE(mean squared error)\n",
    "\n",
    "### R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#create the data\n",
    "X=boston_df.drop(\"target\", axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "#split into train and test set\n",
    "X_train,X_test, y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "# instantiate and fit model\n",
    "model=RandomForestRegressor(n_estimators=100).fit(X_train,y_train)\n",
    "\n",
    "# fit model\n",
    "model.fit(X_train,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8774488514619052"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 is the default metric for regression\n",
    "\n",
    "proportion of varaince in the dependent variable that is predictable from the independent variable\n",
    "\n",
    "compares models prediction to the mean of the target.. values \n",
    "\n",
    "range from -infinity to 1(if  amodel predicts the mean of the target, R^2=0,\n",
    "\n",
    "if it predicts a range of numbers, r^2=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#fill an array with y_test mean\n",
    "y_test_mean=np.full(len(y_test), y_test.mean()) # fillwith the length of y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.488235294117654"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute error(MAE)\n",
    "average of the absolute difference btw the predicted values and the actual values.\n",
    "gives an idea of how wrong our models are\n",
    "mae=|predicted-actual|/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1253529411764696"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds=model.predict(X_test)\n",
    "mae=mean_absolute_error(y_test,y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual values</th>\n",
       "      <th>predicted_values</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>22.682</td>\n",
       "      <td>-0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>30.658</td>\n",
       "      <td>-1.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>17.372</td>\n",
       "      <td>3.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.129</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>17.084</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21.444</td>\n",
       "      <td>1.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>17.8</td>\n",
       "      <td>19.265</td>\n",
       "      <td>1.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>14.0</td>\n",
       "      <td>15.744</td>\n",
       "      <td>1.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>19.6</td>\n",
       "      <td>21.343</td>\n",
       "      <td>1.743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>16.8</td>\n",
       "      <td>21.047</td>\n",
       "      <td>4.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>21.5</td>\n",
       "      <td>19.984</td>\n",
       "      <td>-1.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.9</td>\n",
       "      <td>20.141</td>\n",
       "      <td>1.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8.528</td>\n",
       "      <td>1.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>21.2</td>\n",
       "      <td>21.361</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>18.5</td>\n",
       "      <td>19.077</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>29.8</td>\n",
       "      <td>25.547</td>\n",
       "      <td>-4.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>18.8</td>\n",
       "      <td>19.142</td>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>10.2</td>\n",
       "      <td>8.511</td>\n",
       "      <td>-1.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>50.0</td>\n",
       "      <td>45.782</td>\n",
       "      <td>-4.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>14.1</td>\n",
       "      <td>15.013</td>\n",
       "      <td>0.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>25.2</td>\n",
       "      <td>24.668</td>\n",
       "      <td>-0.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>29.1</td>\n",
       "      <td>24.247</td>\n",
       "      <td>-4.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12.7</td>\n",
       "      <td>14.724</td>\n",
       "      <td>2.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>22.4</td>\n",
       "      <td>24.101</td>\n",
       "      <td>1.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>14.2</td>\n",
       "      <td>14.564</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>13.8</td>\n",
       "      <td>14.659</td>\n",
       "      <td>0.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>20.3</td>\n",
       "      <td>21.497</td>\n",
       "      <td>1.197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>14.9</td>\n",
       "      <td>13.958</td>\n",
       "      <td>-0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>21.7</td>\n",
       "      <td>19.171</td>\n",
       "      <td>-2.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>18.3</td>\n",
       "      <td>21.039</td>\n",
       "      <td>2.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>10.8</td>\n",
       "      <td>10.235</td>\n",
       "      <td>-0.565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>20.6</td>\n",
       "      <td>21.019</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>20.8</td>\n",
       "      <td>21.981</td>\n",
       "      <td>1.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.869</td>\n",
       "      <td>1.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>20.1</td>\n",
       "      <td>20.225</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>48.5</td>\n",
       "      <td>46.078</td>\n",
       "      <td>-2.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>10.9</td>\n",
       "      <td>10.849</td>\n",
       "      <td>-0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>7.0</td>\n",
       "      <td>12.970</td>\n",
       "      <td>5.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>20.9</td>\n",
       "      <td>21.650</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>17.2</td>\n",
       "      <td>12.329</td>\n",
       "      <td>-4.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>20.9</td>\n",
       "      <td>19.887</td>\n",
       "      <td>-1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>9.7</td>\n",
       "      <td>9.133</td>\n",
       "      <td>-0.567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>19.4</td>\n",
       "      <td>20.607</td>\n",
       "      <td>1.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>29.0</td>\n",
       "      <td>26.737</td>\n",
       "      <td>-2.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>16.4</td>\n",
       "      <td>15.851</td>\n",
       "      <td>-0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>25.0</td>\n",
       "      <td>23.457</td>\n",
       "      <td>-1.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>25.0</td>\n",
       "      <td>23.591</td>\n",
       "      <td>-1.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>17.1</td>\n",
       "      <td>17.827</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>23.2</td>\n",
       "      <td>22.063</td>\n",
       "      <td>-1.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>10.4</td>\n",
       "      <td>8.056</td>\n",
       "      <td>-2.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>19.6</td>\n",
       "      <td>19.265</td>\n",
       "      <td>-0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>17.2</td>\n",
       "      <td>19.266</td>\n",
       "      <td>2.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>27.5</td>\n",
       "      <td>23.630</td>\n",
       "      <td>-3.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>23.0</td>\n",
       "      <td>19.630</td>\n",
       "      <td>-3.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>50.0</td>\n",
       "      <td>39.647</td>\n",
       "      <td>-10.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>17.9</td>\n",
       "      <td>11.777</td>\n",
       "      <td>-6.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>9.6</td>\n",
       "      <td>12.562</td>\n",
       "      <td>2.962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>17.2</td>\n",
       "      <td>13.002</td>\n",
       "      <td>-4.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>22.5</td>\n",
       "      <td>20.377</td>\n",
       "      <td>-2.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>21.4</td>\n",
       "      <td>23.882</td>\n",
       "      <td>2.482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual values  predicted_values  difference\n",
       "173           23.6            22.682      -0.918\n",
       "274           32.4            30.658      -1.742\n",
       "491           13.6            17.372       3.772\n",
       "72            22.8            23.129       0.329\n",
       "452           16.1            17.084       0.984\n",
       "76            20.0            21.444       1.444\n",
       "316           17.8            19.265       1.465\n",
       "140           14.0            15.744       1.744\n",
       "471           19.6            21.343       1.743\n",
       "500           16.8            21.047       4.247\n",
       "218           21.5            19.984      -1.516\n",
       "9             18.9            20.141       1.241\n",
       "414            7.0             8.528       1.528\n",
       "78            21.2            21.361       0.161\n",
       "323           18.5            19.077       0.577\n",
       "473           29.8            25.547      -4.253\n",
       "124           18.8            19.142       0.342\n",
       "388           10.2             8.511      -1.689\n",
       "195           50.0            45.782      -4.218\n",
       "448           14.1            15.013       0.913\n",
       "271           25.2            24.668      -0.532\n",
       "278           29.1            24.247      -4.853\n",
       "30            12.7            14.724       2.024\n",
       "501           22.4            24.101       1.701\n",
       "421           14.2            14.564       0.364\n",
       "474           13.8            14.659       0.859\n",
       "79            20.3            21.497       1.197\n",
       "454           14.9            13.958      -0.942\n",
       "210           21.7            19.171      -2.529\n",
       "497           18.3            21.039       2.739\n",
       "..             ...               ...         ...\n",
       "444           10.8            10.235      -0.565\n",
       "355           20.6            21.019       0.419\n",
       "77            20.8            21.981       1.181\n",
       "398            5.0             6.869       1.869\n",
       "104           20.1            20.225       0.125\n",
       "203           48.5            46.078      -2.422\n",
       "381           10.9            10.849      -0.051\n",
       "489            7.0            12.970       5.970\n",
       "69            20.9            21.650       0.750\n",
       "408           17.2            12.329      -4.871\n",
       "255           20.9            19.887      -1.013\n",
       "392            9.7             9.133      -0.567\n",
       "312           19.4            20.607       1.207\n",
       "234           29.0            26.737      -2.263\n",
       "460           16.4            15.851      -0.549\n",
       "324           25.0            23.457      -1.543\n",
       "93            25.0            23.591      -1.409\n",
       "137           17.1            17.827       0.727\n",
       "176           23.2            22.063      -1.137\n",
       "417           10.4             8.056      -2.344\n",
       "131           19.6            19.265      -0.335\n",
       "346           17.2            19.266       2.066\n",
       "365           27.5            23.630      -3.870\n",
       "132           23.0            19.630      -3.370\n",
       "371           50.0            39.647     -10.353\n",
       "412           17.9            11.777      -6.123\n",
       "436            9.6            12.562       2.962\n",
       "411           17.2            13.002      -4.198\n",
       "86            22.5            20.377      -2.123\n",
       "75            21.4            23.882       2.482\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.DataFrame(data={\"actual values\":y_test,\n",
    "                       \"predicted_values\": y_preds})\n",
    "\n",
    "df[\"difference\"]=df[\"predicted_values\"]-df[\"actual values\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.987139352941176"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds=model.predict(X_test)\n",
    "mse=mean_squared_error(y_test,y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.98713935294118"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CALCULATE mseBY HAND\n",
    "square=np.square(df[\"difference\"])\n",
    "square.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R^2 is similar to accuracy.. a good model is oneclose to 1\n",
    "\n",
    "MAE gives beter indcations of how far each model predicts on an average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIDBIT FOR  REGRESSION\n",
    "minimize MSE, MAE while maximize R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Finally using the scoring parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X=heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.90163934, 0.83606557, 0.78333333, 0.78333333])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc=cross_val_score(clf,X,y,cv=5, scoring=None)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is: 82.48%\n"
     ]
    }
   ],
   "source": [
    "# cross validated accuracy\n",
    "print(f\"The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross validated accuracy is 82.48%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc=cross_val_score(clf,X,y,cv=5, scoring=\"accuracy\")\n",
    "print(f\"The cross validated accuracy is {np.mean(cv_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085601538512754"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision\n",
    "cv_precision=cross_val_score(clf,X,y,cv=5, scoring=\"precision\")\n",
    "np.mean(cv_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424242424242424"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "cv_recall=cross_val_score(clf,X,y,cv=5, scoring=\"recall\")\n",
    "np.mean(cv_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.841476533416832"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1\n",
    "cv_f1=cross_val_score(clf,X,y,cv=5, scoring=\"f1\")\n",
    "np.mean(cv_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "X=boston_df.drop(\"target\", axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.622375083951403"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2=cross_val_score(model,X,y, cv=5, scoring=None)\n",
    "np.mean(cv_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76861165, 0.85851765, 0.74941131, 0.47891315, 0.25642166])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#r2\n",
    "np.random.seed(42)\n",
    "cv_r2=cross_val_score(model,X,y, cv=5, scoring=\"r2\")\n",
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.12870588, -2.58823762, -3.3420198 , -3.75555446, -3.34263366])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean absolute error\n",
    "np.random.seed(42)\n",
    "cv_mae=cross_val_score(model,X,y, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "#higher return values are better than lower return values..hence negative\n",
    "cv_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.283214366686064"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean squared error\n",
    "np.random.seed(42)\n",
    "cv_mse=cross_val_score(model,X,y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "np.mean(cv_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 USING DIFFERENT EVALUATION METRIC AS SCI_KIT LEARN FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification evaluation funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier metrics on the test set\n",
      "Accuracy: 85.25%\n",
      "Precision: 0.8484848484848485\n",
      "Recall: 0.875\n",
      "F1: 0.8615384615384615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X=heart_disease.drop(\"target\", axis=1)\n",
    "y=heart_disease[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#make some predictions\n",
    "y_preds=clf.predict(X_test)\n",
    "\n",
    "#Evaluate the classifier\n",
    "print(\"Classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_preds)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test,y_preds)}\")\n",
    "print(f\"Recall: {recall_score(y_test,y_preds)}\")\n",
    "print(f\"F1: {f1_score(y_test,y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression model metrics on the test set\n",
      "R2:0.8739690141174031\n",
      "MAE:2.1226372549019623\n",
      "MSE:9.242328990196082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "X=boston_df.drop(\"target\", axis=1)\n",
    "y=boston_df[\"target\"]\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model=RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#make predictions\n",
    "y_preds=model.predict(X_test)\n",
    "\n",
    "#Evaluate the regression model\n",
    "print(\"Regression model metrics on the test set\")\n",
    "print(f\"R2:{r2_score(y_test,y_preds)}\")\n",
    "print(f\"MAE:{mean_absolute_error(y_test,y_preds)}\")\n",
    "print(f\"MSE:{mean_squared_error(y_test,y_preds)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize ur model for the right evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. IMPROVING A MODEL\n",
    "\n",
    "\n",
    "**** first predictions = baseline predictions\n",
    "\n",
    "**** first model = baseline model\n",
    "\n",
    "\n",
    "From a data perspective\"\n",
    "\n",
    "**\n",
    "could we collect more data?( generally, the more data, the better)\n",
    "\n",
    "** could we improve the data? more info about each sample\n",
    "\n",
    "From a model perspective\n",
    "\n",
    "**\n",
    "is there a better model we can use?\n",
    "simple(linearsvc) and complex models(ensemble method)\n",
    "** could we improve the current model? \n",
    "\n",
    "\n",
    "Hyperparameters vs Parameters\n",
    "\n",
    "improve hyperparameters\n",
    "\n",
    "***    parameters =model finds these patterns in data\n",
    "\n",
    "***  hyperparameters =settings on a model u can adjust to (potentially) improve its ability to find patterns\n",
    "\n",
    "\n",
    "\n",
    "Three ways to adjust hyperparameters\"\n",
    "\n",
    "** by hand\n",
    "\n",
    "** randomly with RandomSearchCv\n",
    "\n",
    "** exhaustively with GridSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyperparameters we can adjust on randomforestclassifier\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Tuning Hyperparameters by Hand\n",
    "\n",
    "#### Hyperparameter get tuned on the validation split \n",
    "#### a model gets evaluated on the test split\n",
    "\n",
    "\n",
    "### Lets make  3 sets, training, validation and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we gonna try and adjust:\n",
    " \n",
    "max_depth\n",
    "\n",
    "max_features\n",
    "\n",
    "min_samples_leaf\n",
    "\n",
    "min_samples_split\n",
    "\n",
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an evaluation function as we would be repeating the task\n",
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs y_pred labels\n",
    "    on a classification.\n",
    "    \"\"\"\n",
    "    accuracy=accuracy_score(y_true,y_preds)\n",
    "    precision=precision_score(y_true,y_preds)\n",
    "    recall=recall_score(y_true,y_preds)\n",
    "    f1=f1_score(y_true,y_preds)\n",
    "    # create a dict to save data so we can return and compare other predictions later \n",
    "    metric_dict={\"accuracy\": round(accuracy,2),\n",
    "                 \"precision\": round(precision, 2),\n",
    "                  \"recall\": round(recall,2),\n",
    "                  \"f1\": round(f1,2)}\n",
    "    print(f\"Acc:{accuracy*100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall:{recall:.2f}\")\n",
    "    print(f\"F1 score:{f1:.2f}\")\n",
    "    \n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212, 45, 46)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# shuffle the data\n",
    "heart_disease_shuffled=heart_disease.sample(frac=1)\n",
    "\n",
    "\n",
    "# split into X and y\n",
    "X=heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y=heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# split data into train, validation and test sets\n",
    "\n",
    "train_split=round(0.7*len(heart_disease_shuffled)) # 70% of  data\n",
    "valid_split=round(train_split + 0.15*len(heart_disease_shuffled))#15% of data\n",
    "X_train,y_train=X[:train_split],y[:train_split]\n",
    "X_valid,y_valid=X[train_split:valid_split],y[train_split:valid_split]\n",
    "X_test,y_test=X[valid_split:],y[valid_split:]\n",
    "                  \n",
    "                  \n",
    "len(X_train), len(X_valid), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "212+45+46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier()\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:80.00%\n",
      "Precision: 0.77\n",
      "Recall:0.92\n",
      "F1 score:0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.77, 'recall': 0.92, 'f1': 0.84}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "\n",
    "# make baseline predictions... tuning our model on the validation split\n",
    "y_preds=clf.predict(X_valid)\n",
    "\n",
    "# evaluate the classifier on validation set\n",
    "baseline_metrics=evaluate_preds(y_valid,y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:82.22%\n",
      "Precision: 0.84\n",
      "Recall:0.84\n",
      "F1 score:0.84\n"
     ]
    }
   ],
   "source": [
    "# n_estimators=100 is changing hyperparameters by hnad\n",
    "np.random.seed(42)\n",
    "\n",
    "#create a second classifier with diff hyperparameters\n",
    "clf_2=RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train,y_train)\n",
    "\n",
    "#make predictions with diff hyperparameters\n",
    "y_preds2=clf_2.predict(X_valid)\n",
    "\n",
    "#evaluate the 2nd classifier\n",
    "clf_2_metrics=evaluate_preds(y_valid,y_preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing max_depth\n",
    "clf_3=RandomForestClassifier(n_estimators=100,\n",
    "                              max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Tuning Hyperparameter using RandomizedSearchCv  a module in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.2s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.1s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.1s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.1s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   3.1s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.3s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.3s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.3s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.4s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   1.4s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.7s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.8s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.6s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.5s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   2.6s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   2.6s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   2.7s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   2.6s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   2.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   47.5s finished\n",
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#create a dict with the hyperparameters u will like to adjust as the keys and the values u will like to try as the values\n",
    "\n",
    "#get all the values u can try by reading the documentations\n",
    "grid={\"n_estimators\":[10,100,200,500,1000, 1200],\n",
    "      \"max_depth\":[None,5,10,20,30],\n",
    "       \"max_features\": [\"auto\",\"sqrt\"],\n",
    "       \"min_samples_split\":[2,4,6],\n",
    "        \"min_samples_leaf\":[1,2,4]}\n",
    "      \n",
    "np.random.seed(42)\n",
    "      \n",
    "# split into X and y\n",
    "x=heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y=heart_disease_shuffled[\"target\"]\n",
    "      \n",
    "# split into train and test sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "      \n",
    "# instantiate RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_jobs=1) # n_jobs stands for how much of my computer processor i am dedicating to this model, -1 means all of it\n",
    "\n",
    "# setup RandomizedSearchCV\n",
    "      \n",
    "rs_clf=RandomizedSearchCV(estimator=clf,\n",
    "                          param_distributions=grid,\n",
    "                          n_iter=10, # number of models to try\n",
    "                          cv=5,\n",
    "                          verbose=2)\n",
    "\n",
    "\n",
    "#fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train,y_train);\n",
    "\n",
    "# it runs this 50 times(n_iter=10*5(hyperparameters)) diff combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_clf.best_params_ #the combination that gave the best result.. and becomes the one used to make preds by default,.it saves us the stress of finding it ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:81.97%\n",
      "Precision: 0.77\n",
      "Recall:0.86\n",
      "F1 score:0.81\n"
     ]
    }
   ],
   "source": [
    "# make predictions with the best hyperparameters\n",
    "rs_y_preds=rs_clf.predict(X_test)\n",
    "\n",
    "# we dont used the validation set here because the purpose of the validation set which was to vary diff hyperparameters before using the best on the main test set has already been taken care of by the randomizedsearchcv module\n",
    "\n",
    "#evaluate the predictions\n",
    "rs_metrics=evaluate_preds(y_test,rs_y_preds)\n",
    "\n",
    "# this dosent do better than when we tune hyperparameters by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### start with tuning by hand, then by randomizedcv then finally gridsearchcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Hyperparameter tuning with GridSearchCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_split': [2, 4, 6],\n",
       " 'min_samples_leaf': [1, 2, 4]}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gridsearchCv functions like brute force method... \n",
    "# it goes through every possible outcomes, every single combination 6*5*2*3*3*5(cv)=2700 \n",
    "\n",
    "#reduce the no of hyperparameters grid has to go thru\n",
    "# take the best params and use to influence the grid param.. use it to reduce search space of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_2= {'n_estimators': [100, 200, 500],\n",
    "         'max_depth': [None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_split': [6],\n",
    "         'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posible_ways=(3*1*2*1*2)*5#(hypertuning param)\n",
    "posible_ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.4s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.7s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.7s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.7s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.5s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.8s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.4s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   1.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.5s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   2.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.8s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   46.7s finished\n",
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# split into X and y\n",
    "x=heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y=heart_disease_shuffled[\"target\"]\n",
    "      \n",
    "# split into train and test sets\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "      \n",
    "# instantiate RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_jobs=1) # n_jobs stands for how much of my computer processor i am dedicating to this model, -1 means all of it\n",
    "\n",
    "# setup GridSearchCV\n",
    "      \n",
    "gs_clf=GridSearchCV(estimator=clf,\n",
    "                    param_grid=grid_2,\n",
    "                    cv=5,\n",
    "                    verbose=2)\n",
    "# it doesnt have n-iter cos it goes thru all possible combo\n",
    "\n",
    "\n",
    "#fit the GridSearchCV version of clf\n",
    "gs_clf.fit(X_train,y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:78.69%\n",
      "Precision: 0.74\n",
      "Recall:0.82\n",
      "F1 score:0.78\n"
     ]
    }
   ],
   "source": [
    "gs_y_preds=gs_clf.predict(X_test)\n",
    "\n",
    "#evaluate the predictions\n",
    "gs_metrics=evaluate_preds(y_test,gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lets compare our different models metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAINCAYAAADrzqHiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3yN5//H8fc5iQxJZJDYIvaMGq09q4guDUpVdRlVXUZrdOhQrbb2LK2tSrVVK6j6KtX6qaLVKkVUUpQgIiFknPP7I1/59jQhIbmcE17Px6OPR3Ld63Ofc+Hd677u+7bY7Xa7AAAAYIzV2QUAAADc7AhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDB3ZxeQG/Hx52Wz8biwy4oW9dXp00nOLgMFBP0FuUVfwbWgv2RltVoUGOiT7bICEbhsNjuB61/4PHAt6C/ILfoKrgX9Jfe4pAgAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGFYi7FAEAN7/k5PNKSkpQenqqs0tBLpw8aZXNZnN2GTeEm1sh+fr6y9s7+0c+5AaBCwDgdKmpKUpMjFdAQDEVKuQpi8Xi7JKQA3d3q9LSbv7AZbfblZp6SWfPnpK7eyEVKuRxXfvhkiIAwOkSE8/K19dfHh5ehC24FIvFIg8PL/n4+Csp6ex174fABQBwurS0FHl6eju7DOCKvLy8lZqact3bE7gAAE5ns6XLanVzdhnAFVmtbrLZ0q9/+3ysBQCA68alRLiyvPZPAhcAAIBh3KUIAHBpfkW85eXp3H+uLl5KU+K55GverkuXe9WgwR0aNuxVA1Xl3vHjx9S163169dU31b59R61Zs1KjR7+hL75YrZCQ4k6t7VZB4AIAuDQvT3fdO/grp9awcuz9SnRqBfmrceNmmjFjjgIDg5xdyi2DwAUAwC0mMDBQgYGBzi7jlkLgAgDAoNTUFH3wwTv6+uu1cnd3V+vWd+npp59V4cI+Sk9P1yefzNf69VE6evSorFaLKleuqj59+qtevQaSpEuXLmry5AnaunWzzp6NV8mSpXTPPZ3Uo8cjmcdISDirGTOmaMuWb3XhwgVVrVpN/fs/q/Dw27Kt6d+XFN9++3WdPn1abdrcqYUL5+nEib8VGhqm/v2fVcOGjTO3+/vv45o2bZK2b9+mtLRUhYfX1bPPDlRYWAWzH+JNgMAFAIBBGzasV+3adfTaa6N0/PhRffjhNJ09e0ajRr2nadMmasWKL/XUU8+qQoWKiouL09y5s/Taa8O0bNkqeXl5aeLEsfrxx//TM8+8oMDAIG3b9r2mTZuowMBARUTco0uXLun5559WfPwZPfXUAAUFFdPy5Z/rhRee1tSps1S9es1c1bl37x6dPPm3evd+Sj4+vvrooxl65ZWX9OWXUfL19dXZs2fVv/+T8vb21pAhw+Tt7aWFC+fp6ad7a86cRSpRoqThT7JgI3ABAGBQQECAxo6dJE9PL0mSu7u7xo4do8OHo3XqVJz69Rugzp0fzFzf09NDL7/8kg4fPqTq1Wtq9+6datCgoe68s50kqV69BipcuLD8/QMkSevWrdGhQwc0a9Y8VatWQ5LUqFET9enzqD78cKomTJiWqzqTkpI0e/YilSpVWpLk7e2tZ57pq127dqh581ZasmSRzp1L0IcfzlFISHG5u1vVoEFDdev2gObN+1hDh76Sb5/ZzYjABQCAQY0bN8sMW5LUrFkrffDBu9q3b6/eeOMdSVJ8fLxiYo7or79itHXrFklSamrGS7zr1Wug5cs/V1zcCTVp0kzNmjVX7959M/e3c+ePCg4OUbVq1SRlvNvQapWaNWuuefNmy25Pl5ub9b/tFlmt2T9PqmjRYplhS5KCg0MkScnJFyVJP/30o6pWra6goKJKS0uTZJWbm7tuv72hfvzx//Lhk7q5EbgAADDo33cCBgRkjEydOhWnffv2auzYd/X773vl5eWlsLAKKl68hCTJbs9Y/7nnBis4OETr10dp3Lj3NG7ce6pcpYYe6zNQoeUr6u8Tp3Xy5Ak1a3ZHtsffvffIfwOSdOLMhSsGLi8vL4ffrVbrf+vICHHnziXor79i1apVoyzbursTJ3LCJwQAgEGJiY4PlIiPPyNJ8vT00uDBz6pSpapasGCpQkPLy2q16ocfvtOmTRsz1/fw8NCjjz6pRx99UqdOndCXK9dp+bIFmj5ptN4d97G8C/uoVOlQPfXssGyP7+fnr/j403k+Dx8fX9Wvf7v6939WkuTmZlV6ui3P+71V8KR5AAAM2rFju9LT//cOvv/8Z4MkqVat2kpISFC3bj0UFlYhc0Rp27bvJWWMLKWkpKhHj85avHihJKlEiZK6q0MnNW7WRmdOn5QkVa8ZrtOnTigwsKgqVKya+d9PP27V+jVfyC2fRp9uu62eYmKOKDQ0TNWq1VD16jVUrVoNffXVl/r663X5coybGSNcAAAYFBd3QiNHDlenTl104MAfmjVrujp2vFflypWXj4+P5s79SBZLxsuRN23aqNWrMx7ympycLA8PD1WvXkNz5sxSoULuqlKlqnbs/l2bN63T7Y1aSpJatIrQ+qjleufNF3VfZA8FBRXTrp+2KWrVZ3qga698e0dl9+4Pa9261Ro4cIC6deshf39/rV69UuvWrdHw4a/lyzFuZgQuAAAM6tSpixITz2n48MHy9PRS167d1adPf7m7u+udd8Zq2rRJeuWVoSpc2EeVK1fVlCkzNWTI8/rll91q3LiphgwZIX//AC1evFBnzpyWX5EAtWrTUV26PyFJ8vL21qtvTtCni2bpk3nTlZx8QSHFS6rXE8+qXcQD+XYewcEhmj59tj78cIrGjHlbaWmpKleuvF5//W21bds+345zs7LY7Zen5bmu06eTZLO5fJk3THCwn+LibqaXTMAk+gtyy5l95e+/j6hEidBslxXkdynmN3d3qw7Gns3TPiqVDVBaWt7nXrm7W/NlPwXJ1fqplHEXaNGivtkuY4QLAODSEs8l31TvMcStiUnzAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAzj1T4AAJcW6O8hdw9Pp9aQlnJJ8Qkp+b7fZ57pKzc3d02cOE2SFB19SKNGjdThw4dUrlyo5s37NFf7uXDhvJYvm68d279Twtl4BYeUVNv29+nOdvfJYrHke924dgQuAIBLc/fwVPTbnZ1aQ4WXP5eU/4Hr3+bN+0jHjx/T6NHvKzCwaK63mzrhLR06uE+dH3xMJUuX02+//KR5H0/WhQvndd8DPQxWjNwicAEA4CISEhJUsWIlNW7cLNfbHDl8UD/v2q5nB72mho1bSZJq1a6nC+eTtGr5YgKXi2AOFwAABtntdi1Zskg9enRWmzZN1b17pJYty3qpsFmzBtqxY7t2796pZs0aaM2albnbv+xq3fYe1axVz6G9ZOlyunDhvBITE/LlPJA3jHABAGDQtGmTtHTpJ+rRo5fq1WugPXt+1sSJY2W1ujmsN2PGHE2c+L7S09M1aNAwlS5dJlf7Lx9WWU/2G5Sl/acft8o/IEi+vkXy5TyQNwQuAAAMSUxM1NKln6hbtx7q12+AJOn22xsqLu6kdu/e6bBurVq1Vbiwr9LT01SrVu08HXft6s/1+2+71fOxAUyadxEELgAADPnttz1KT09XixatHdqHDn1FUsZdivltfdSXWjRvmho2bqX2HSPzff+4PgQuAAAMOXcuY/5UYGCQ8WPZbDZ9uvBDrVn5mZo0u1P9nhnG6JYLIXABAGCIj4+vJCk+Pt5hTtbRo3/p5MkTstvt+XKctLQ0TZs4Stu3bVbHe7vqoUeeImy5GAIXAACG1KhRS+7u7tq6dbPDvKz582dr166fFBJSPF+OM2vae/rx/7ao52NPq8PdXfJlnzmx2+1yd8/bww5sdrts6fkTOl0dgQsAAEMCAwPVuXM3LV68QO7u7qpTp65++WW3oqJW6aWXXtbatavzfIxdP23T1i0bVK9BE1WqXEMH/9jrsLx8WGW5FyqU5+P8m8Vi0aEzMXnaR8WgcrKJwAUAgNOlpVz675PenVvD9Row4HkFBgZqxYovtWjRPJUuXUbDh7+miIh78iVw/fh/myVJO3d8r507vs+yfOKMJSpaNDjPx0HeWOz5dQHZoNOnk2SzuXyZN0xwsJ/i4hKdXQYKCPoLcsuZfeXvv4+oRIlQpxy7IHF3t+pg7Nk87aNS2QClpdnypZb8GOHKj1pulJz6qdVqUdGivtkuY4QLAAAXlJ6ens2keqvS09Mzf7NIsrq5Ca6PwAUAgAt6/vn+WR6O+m/FgotrwrTFN6gi5AWBCwAAF/TSSyN04cIFhzY3N6tiT/zvsm8h9/yfDA8zCFwAALigcuXKZ2lzd7eqkG/e5nDBOfL2AA0AAADkiBEuwAC/It7y8szbHy9baoqshTzyXIstLSXP+4DrC/T3kLuHZ572QV+5NeTHA0tx7QhcgAFenu66d/BXedrHyrH3K/rtznmuJeP5Rdf/DCEUDO4ennnuL/SVW4PFYtGl44fyvB/PkhXzoZpbBxEXAADAMAIXAACAYQQuAAAAw5jDBQBwaX4BnvLKhxtI8uJiaooSzxaM+W17f9ut0a8P0qtvTlTV6rWdXY7LWbNmpUaPfkNffLFaISHFb9hxCVwAAJfmVchDDy7p79QalnabrkRuKEAecEkRAADAMEa4AAAwpEuXe9WyZRv98cc+7d+/T/fee7+efXaQDhzYr9mzZ2nPnt1KTExUUFBRtWp1p5566hl5emY8T61ZswYaMmS49u79VZs3b1J6erqaNGmqyIeekr9/YOYxvvl6paJWfqbTp06qYqVqatEmIksdB//Yq2WfzlF09H65WS2qX7uWnnq0p0qGhEiSojb+RxNnfax3Xh6uqXPm6UjsXypTqqQGP9VXFotFkz6areiYGJUuUULPPvm46odf+VLlnp279dmCT/TXkRi5ubupeq2a6v54L5UqWyZznR+/36blny7VsZi/5OdXRO3aRahPn/7y8PjfpeNNm77RkiWf6ODBA0pLS1WpUqXVpUt3PfBAF0nSzp079NxzT+nFF0do3ryPlZ6epjffHKM6dW7TDz98p3nzZuvgwT/k6+unVq3aqG/fASpcuPD/6tzzi5Yu/UQHDuxXYGCQunbtru7de17nN50zAtcNlh8PJ0xJS1FwsF+eaylIcxIAoKBatuxTde36kHr2fEx+fn6KizupAQP6qnbtOnr55dfl7l5I27Z9ryVLFqlYsWJ6+OFHM7edMWOyWrRorbfeekd//fWXpkwZr4spdvV/boQkaX3Ul5o/e7Lad4zUbfUa6rc9uzT7w3EOx//1l5/03ttDVbtOAz31zDD5F7Zo5ozJGjDsFX007j0FBQRIklJSUvXOpCl6ons3+Rfx06SP5mjk+2Pl7u6unp0jFejvr5kLF+nNsRO0dNZ0Zfcv2cnjf2vcW6PV8q626vbYIzqfmKil8xfp/ZFvadzHM2SxWLT1P99q2vvj1fzO1nru6YE6ejRW06dP1fHjR/Xuux9IkjZv/lavvDJU3bs/rH79+uvixYv6/PPPNHbsu6pRo4Zq1qwlN7eMi3SzZk3T0JdeVtL586pevYa2bt2iYcMGqWXLNnr00Sd05swZTZkyQadPn9Zbb72bWev7749Wnz5PqU+f/lqx4ktNmTJB5ctXUKNGTfLz689E4LrB8uvhhPkxn4E5CQBgXkhICQ0Y8LwsFoskadu271WlSlW99da7mSMut9/eUDt2/J92797pELgqVaqiESNG/ncdaf/+vdr4n42SMp4Yv/zzhWrUtLUeefwZSVLtOrcr+cJ5ffP1ysx9LPnkI5UuU16Dh42W1WpVpbIBql4yUD0HPK8ly1eo/2O9JEnpNpse7/6gOrRpJUmKOXpM0+bO10sD+uvutm3+u066XntvrI4e/1tFQqtnOddDfxxQyqUU3d+tiwKLBkmSigYX00/btuti8kV5eXvp0znzVfeOBnpq8POqGFROSQcPqUi/ARo5/j1tW7NatapU0x8/7VD7Fq3V+55Omfuu8OiTivxhq7Z9vV6hnt5KPnpMknRv67vUus2dSkuzSZJmz56patWqa9SoMZnb2u12ffrpQl24cD6zbcCA53XvvRn7r1UrXFu2bNLOnT8SuAAAKIjCwipkhi1JatSoiRo1aqK0tDQdPhyto0djdejQQcXHxyswMMhh29q16zj8HhJSXJcuXpQkHT8Wq3MJ8ap/e1OHdRo2aZUZuC5eTNaf0X+oS7fHZbX+b9p28eBg1a5RTbt+2+uwbfXKlTN/DvT3lyTVrPq/tiJ+GVdXks6fV3YqVauiQh4eevWFIWrYrInqNKiv6uG1VLFqFUnSsdi/dObUaT3Qo5vS09OVlpam9PR03V67jgq5u+unPb+oVpVq6v7fIJR8MVmxx4/p6Im/9Ud0xtPx09LTHD/fsuUyf7506aL++GOf+vZ92mGde+65X/fcc79DW506t2X+7OXlpcDAICUmJmV7Xvkh14Fr1apVmj59umJjY1W6dGn169dPnTp1uuL6Z86c0fvvv68tW7YoJSVFdevW1fDhw1W+fPn8qBsAgAIhKMgxRNlsNn344VR98cVnSk6+oJCQ4qpRo6Y8PT1ltztue3k+12UWi0V2e8ZITlLSOUmSX5EAh3UCAotm/nzhfJLsdrv8AxxrkKQg/wCdOHnKoa2wt3eW9f5dw9UEFy+uV8eM0orPvtB/1m3Q2q9WqbCvj+66u6O69uqhxHOJkqSPJ03Tx5OmZdn+9NkzkqSExHMaP3umvt+xXbJYVKZESdWsUk2SsnxGl4OhJJ07d052u12BgYHKiZeX47lardbMz9aEXAWuqKgoDRkyRL169VLz5s21YcMGDR06VF5eXurQoUOW9e12uwYMGKCYmBi9+OKLCggI0KRJk9SrVy+tXLlS/v/4cACYlZKemuc5f8z3A/LPwoVztXTpJ3rxxRFq0aK1fH19JUl9+vS6pv34+WX8W3rubLxDe1LiucyfCxf2lcViUcJ/g8w/nY6Pl3+RvM8H/reKVato4CvDlJaaqv2//a5votbpqyWfqXzFMJUsU1qS1LPvE6pao4bK+JfQhdi/Mrf1/+8I2uipExV7/JjeGz5SNSpXkUehQrp46ZKiNn1z1WP7+GR8lvHxZx3aL1w4rz17flHNms57LlmuAte4ceMUERGhESMyJuk1b95cCQkJmjhxYraB688//9TOnTs1ZsyYzFGwihUrqm3bttq4caMeeOCBfDwFAFfj4VYoz3P+mO8H5J9fftmtihUrq2PHezPb4uJO6tChQ6pVK/eBoETJMipaNET/98MmNWl+Z2b7zh3fZ/7s5e2t8hWqaNv3m3TvAz0yLyuePHVKv+7br8i7s97RmBfrVqzSmi++0gezpqlQoUKqeVu4wipX1P9t2arTp06pQeOGKuLvr1MnTiqi030Zc7gKeervuJMaO2u6ut59n0oEh+jXP/bpvrbtdVuNmpn73v7zLkm66ihU4cKFValSFX3//WY98shjme2bN2/SqFEjtWzZqnw932uRY+CKjY1VTEyMBg0a5NDevn17RUVFKTY2VmXLlnVYdulSxl/MPj4+mW2XR7XOnnVMnQAA3EqqV6+pefM+1qJF81SjRi0dPRqr+fPnKDU1RcnJybnej8ViUbeefTRt4tv6+MNxuqNRcx34Y6++Wb/SYb0HH3pC7709XGPffVlt29+n6N8tmjVjsgp7e+vBe+/J13OrWSdciz+ep/FvvaN293aU1c1N36xZp0IeHqp7x+2yurmpa68emjP1Q1ksVnVo3UEnD/yh+Z8vVdKF86oUWl6SVLVCJW3YulmVQsNUNDBIvx3Yp8UrvpTFYtHFS1f/n7/evftp+PAhevPNV9W+fUfFxZ3QjBlT1KHD3SpRokS+nu+1yDFwRUdHS5LCwsIc2kNDQyVJhw8fzhK4qlWrpoYNG2rq1KmqUKGCAgMD9e67GXdjtG3bNr9qBwCgwHnkkceVkHBWS5d+oqSkJBUvXkLt23eU1WrVggVzdf58UualsZw0aXanrBarln++QN99u05lylXQE/0GauqEUZnr1K5zu4a+MkafL52rSWPfkLe3txqE11S/R3qqaFDOc52uRZnQchry+iv6fNGnmjJmnGzp6QqrXEnDRo1UiVIlJUltItrLu3BhrVr2pb5Zs1aFvbwUXq2Gnniwh4ICMuoZ+tQzmjzvY02a91HGfkuU1MAn+mnD1s3as//3q9bQrFlLvfPOWM2ZM0vDhw9WQECg7r33AT32WO98PddrZbHb/z39zNGqVas0ePBgffPNNypT5n8PLTty5IjatWun8ePHq2PHjlm2i46OVu/evXX06FFJkoeHh6ZOnaoWLVpcc5GnTyfJZrtqmQVGcLCfSz0WIi4uMc/7QVbBwX66d/BXedrHyrH357mvSPnTX+grri+//m5x1vf8999HVKJEaLbLeJfi/7i7W3UwNm9XiiqVDdCl44fyXItnyYo6dCYmT/u4/FiIvPKtVDHzsRAmXa2fSpLValHRotmH5RxHuC7nsX/e0vrP9n/eZnrZoUOH1L17d5UrV04jRoyQl5eXli5dqueee04fffSRGjRokNNhHVyp+BspJTVdHoXcnF1GvsuPB6ji1kBfuTU463s+edIqd/fs3zaXnJSqZKXe4IqyulJ9cA034vuxWq3X/Wckx8Dld/mZG0mOz6Y4/99ncFxe/k9z586VJM2ePTtz7lbTpk3Vo0cPjR49Wl988cU1FekKI1z5MWIhZYxauBJGLcy4GcMJfcW15Vefc9b3bLPZbsgIRUFH6LuyG9F/bDbbVf+MXG2EK8dv7vLcrZgYx2HDI0eOOCz/p2PHjqlixYoOj3+wWCyqX7++Dh48mNMhAQAAbio5Bq7Q0FCVKVNGa9eudWhfv369ypcvr1KlSmXZJiwsTAcOHFBCQoJD+88//6zSpUvnsWQAAICCJVfP4RowYICGDx8uf39/tWrVShs3blRUVJTGjx8vKeOp8jExMapUqZJ8fX312GOPacWKFXryySfVt29feXl56auvvtL27dszt4Hz2VLy/hLstIuXFJ+Ykk8VAQBwc8pV4IqMjFRKSopmz56tzz77TGXLltWYMWMy707ctGmThg8frvnz56thw4YqU6aMFi9erPfff1/Dhg2T1WpVlSpVNGfOHDVpYualkLh2Vg8Pbb0/b3c1Nf3qc4nABQDAVeX6XYrdu3dX9+7ds10WGRmpyMhIh7aKFStqxowZeasOAADgJsDtDgAAAIYRuAAAAAzL9SVFALeu/LjBQuImCwC3LgIXgBzlxw0WEjdZ4PoE+nnI3cvTqTXc6P9ZOH78mLp2vU+vvvqm2rfP+vq8y154+iHVrF1fffoPuWG15beHX3ha9WrW1uA+eX9lnSsjcAEAXJq7l2e+BP68uNH/s1C0aDHNmDFHZcqUvWHHhFkELgAAXIyHh4dq1art7DKQjwhcAOBEfkW85eXpGn8Vp6Sn5stcvYupKUo8eykfKir4UlNTNWPGFG3YsFbnz59X48bNVKtWbU2ePF7ffbdDkvTMM31VokRJXbhwQTt2bNcddzTSgAHPZ7mkePDgAU2dOkG//PKzfP2K6MEevXM8fsqlS1o0f7p27vheiecSFBxSQl06d1aXNk0z10k4l6gPFyzS1u0/6sLFZFWtUEH9evVU7erVMtc5m5Cgjxcv0f/t3KXT8fHy9vJS/QYN1enR7gouHiJJGjX0ZRULCVFycrJ+3fWzwuvX1fMjXtKFCxf02byF2r71ByVfSFaZ0HJ6sNfDqlW3zv8+p/Q0zVg0Txu2btHFSxdVs0o1Pf94H5UKKZ4v34MrcI0/5QBwi/LydNe9g7/K835Wjr0/z/vwcCukB5fkfR7N0m7TlSgClySNGTNK//nPBvXp01+hoWH66qvP9eGHU7Os9/XXa9W2bTuNHv2+LBZLluVxcSf1zDN9VK5cqJ5+/mVduHBeny6cqXMJ8Vc9/oK5U/Xrzzv0cK/+KhIQqF92bdfkyRPkq1R1aNNKl1JSNGjkG4pPOKe+j/RQUECAvlr3tQaNfFOT3n5T1StXkt1u10tvjdaF5GT1e6SnggIDdOjPI/p48VLFJ53VS2++lnm87zdtVqMWzTTw1WGyyCJberrGvPKG/j52TF0f6aESpUppY9Q6vT/yLb0x/j1VDConSdq4dYsahN+moU89o/izZzV90VyNnjpRU94YnafP35UQuAAAMODo0b+0bt0avfDCi+rc+UFJUsOGjfXoo911+HC0w7ru7u566aWX5enpJSlj0vw/LV26WOnpNo0fP1lx5zLaSpYqq9dHDLhqDfv2/qxa4fXVqGlrSVKNmrepVPFA+RfJGMlcv2mzDh2J0Yz33lG1ShUzaqxXV0+9NFyzFn2ica+/prjTZ+Tt7a3nej+hWtWqSpLq1qqpv88la8WKLx2O5+bupt7PPS0Pz4ybHHb+3486uG+/XnzjFd12ewNJUvXwWnrthRe19+c9uvP2VpKkkGLF9ObAl+TunhFLjp74W4u++lzJFy/K28srF5+26yNwAQBgwM6dO2S329WqVZvMNqvVqtat2+rw4ZkO65YuXSYzbGXn5593qXbtOvL3D1DcubOSpEqVq6tosZCr1lCj5m365uuVOnMmTnXqNtRt9RrpiSf66NLxQxk17tmjYkFBqhRWXmnp6ZnbNW5QXws//0KpqakKKVZUE996XXa7XcdPntRfx44r5ugx/fLLbqWlpTkcL6REicywJUl/7P1dhQoVUp0G9TPb3Nzc9PbkcQ7bVa9YJTNsSVKJkIzzOp98gcAFAACu7OzZjMt9AQGBDu1BQUWzrBsYmLXtn86dO6eyZbPesRiQw3Y9Hx+goKLB2rplg+bPnqz5syerdu1wvfD4I6oUVl4JiYmKO31ad3bJ/tV9CYmJKhYUpK+/3aKZCxfp5KnTKuLrq8oVwuTl5SW73e6wvn9ggMPviecS5edfJNvLpP/k5en42A/rf9e32+zZrV4gEbgAADCgWLFgSVJ8fLyKFVk7bQ8AACAASURBVCuW2X45iF2LgIAAnTlzJkt7UuK5q25XqJCH7u/cU/d37qlTcSe066cftPLLRRo1YZLmThwn38KFFVqmtEY8/2y22/v7+emXvb9r9KTJ6nLP3XrwvnsUXDQj5M1ctlJ79vxy1eMX9imsxHOJWdoP/XFAhQoVypzDdSvg1T4AABgQHn6b3Nzc9N13mxzat2z59pr3Vb/+7frll906ffpUZtvR2D918sTxK26TmpqiF59/VGtWLpUkFQsurrs6dFK7du0Vd+q0JKlOzZo6EXdKxYICVa1Sxcz/tm7/UZ+vXiN3d3f9uv8P2Wx2Pd79wcywlZ6erh9//L8sI1z/VrVGdaWmpGjPzt2Zbbb0dE17b7zWfrXymj+HgowRLgAADChduozat++oqVMnKiUlRaGhYVqzZqUOHNif4yW2f3vwwYe0atVXeu65p3XPAz2VnpaupYs/dpj39G+FCnmoQsWq+uKz+XJ3d1fZchV1/FisVq9eqZZNGkmSItq00herozRo5Jvq2TlSxYoG6YcdP2npilV6rFtXWSwWVa9cSZI0cdbHat+6lRKTkvTlmrU6cOAP2e12pVy65DBv65/qNbxdFatU1vSxE9T1kYdVLCRY/1n3teJPn1ZEp/uu6TMo6AhcAAAYMnjwUHl7e2vevI916dIlNWvWUvff31nr1q25pv34+wdo2rSPNHnyOH04ZYw8vbx1z/3dtO37TVfd7vG+A+VXxF+rVyxVwtl4FfEP0H33ddKj93WQJBX29tbk0W/qwwWLNHXOPF24mKxSxYvr+T5PKLJjhKSMOxJf6NtbS79aqY3ffa/AAH/VrVVT7777gYYOHax9v+1VeL262R7f6uamoaNG6tM587V03kJdunRJYZUqavjoN1S2fOg1fQYFHYELAODS0i5eyni1jpNruFbnziVo27Yf1Lt3fw0c+FJm+6uvDlOZMmUyf58yZWaWbUuWLJX5YNTLSpcuow8+mKCDsWcz2yLu6XrVGry8vNXzsQHq+dj/Hh9RqWxA5l2KkhQUEKDhz1798RIPRLTXAxHtHdo8S1bUojXLM39/Zczb2W7r4+urJ599Wk8++3S2yxdNmJalrX2L1mrfovVVaypoCFwAAJcWn5hSIF967unpqfHj39P69bXUuXM3eXp6avv2bfr2240aNuxVZ5eHG4zABQCAAZ6eXho/fopmzpyut956TZcuXVRoaJheeeUNtWsX4ezycIMRuAAAMKRatRoaN26ys8uAC+CxEAAAAIYxwgUAyFe2lBQFB/td0zYnT1rl7v6/MQC7za70m+gp4wCBCwCQr6weHtp6f+dr2sb7+WeVeCFVFmU8n8q3UkWJwAUXktNDXnPCJUUAgNPZzycpPefVAKdJTU2Rm9v1j1MRuAAATpfyn291NileabLLLka24DrsdrtSUi7p7Nk4+foG5LzBFXBJEQDgdLZD0bq4crXOtG4pi4+vEo8dkc1mc3ZZLsdqtSrp3IU87ePYsQSlJVz7C7T/zd1+REnnT+etlot2XTqf91rOGe4vbm7u8vMLlLe3z3Xvg8AFAHAJtkPRungoWpJU76vPFReX6OSKXE9wsJ+GDf4qT/tYOfZ+Rb99bXPsslPh5c/14JL+edrH0m7Tr3m+X3YKQn/hkiIAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACG5TpwrVq1SnfffbfCw8MVERGh5cuXX3V9m82m6dOn684771R4eLjuvfderV69Os8FAwAAFDTuuVkpKipKQ4YMUa9evdS8eXNt2LBBQ4cOlZeXlzp06JDtNqNHj9aSJUs0aNAgVatWTatXr9bgwYPl6+urli1b5utJAAAAuLJcBa5x48YpIiJCI0aMkCQ1b95cCQkJmjhxYraBKyYmRosWLdKbb76prl27SpIaN26sP//8U1u2bCFwAQCAW0qOgSs2NlYxMTEaNGiQQ3v79u0VFRWl2NhYlS1b1mHZhg0b5OXlpU6dOjm0L1y4MB9KBgAAKFhynMMVHR0tSQoLC3NoDw0NlSQdPnw4yzb79+9XWFiYvv/+e913332qUaOG2rVrpzVr1uRHzQAAAAVKjoErMTFRkuTr6+vQ7uPjI0lKSkrKss2ZM2d0/PhxjRgxQj179tRHH32kmjVrauDAgdq2bVt+1A0AAFBg5HhJ0W63S5IsFku27VZr1syWmpqqM2fOaMaMGWrdurWkjDlc0dHRmjJliho1anRNRRYt6pvzSnCa4GA/Z5eAAoT+gtyir+BauHp/yTFw+fllnMC/R7LOnz/vsPyffHx85ObmpqZNm2a2WSwWNWnSRMuWLbvmIk+fTpLNZr/m7fKTq3+RzhQXl+jsElwO/eXK6C+O6CtXRl/Jiv5yZa7QX6xWyxUHiXK8pHh57lZMTIxD+5EjRxyW/1NoaKhsNpvS0tIc2lNTU7OMlAEAANzscgxcoaGhKlOmjNauXevQvn79epUvX16lSpXKsk3z5s1lt9sVFRWV2ZaWlqYtW7aofv36+VA2AABAwZGr53ANGDBAw4cPl7+/v1q1aqWNGzcqKipK48ePl5QxST4mJkaVKlWSr6+vGjdurJYtW2rUqFG6cOGCypcvr08++URHjx7V2LFjjZ4QAACAq8lV4IqMjFRKSopmz56tzz77TGXLltWYMWPUsWNHSdKmTZs0fPhwzZ8/Xw0bNpQkTZo0SRMnTtTMmTOVkJCgGjVqaPbs2apVq5a5swEAAHBBuQpcktS9e3d1794922WRkZGKjIx0aPPy8tLQoUM1dOjQvFUIAABQwOX65dUAAAC4PgQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGJbrwLVq1SrdfffdCg8PV0REhJYvX57rgxw/flz169fXtGnTrqtIAACAgixXgSsqKkpDhgxR06ZNNXXqVN1xxx0aOnSo1q5dm+O2drtdI0aMUFJSUp6LBQAAKIjcc7PSuHHjFBERoREjRkiSmjdvroSEBE2cOFEdOnS46raffPKJoqOj814pAABAAZXjCFdsbKxiYmLUrl07h/b27dsrOjpasbGxV932gw8+0FtvvZX3SgEAAAqoHAPX5dGpsLAwh/bQ0FBJ0uHDh7PdzmazadiwYYqIiFCLFi3yWicAAECBleMlxcTEREmSr6+vQ7uPj48kXXFu1rx58xQbG6sZM2bktUYAAIACLcfAZbfbJUkWiyXbdqs16yBZdHS0JkyYoEmTJsnPzy/PRRYt6pvzSnCa4OC8f8e4ddBfkFv0FVwLV+8vOQauy4Hp3yNZ58+fd1h+WXp6uoYNG6YOHTqoadOmSktLy1xms9mUlpYmd/dczdXPdPp0kmw2+zVtk99c/Yt0pri4RGeX4HLoL1dGf3FEX7ky+kpW9Jcrc4X+YrVarjhIlOMcrstzt2JiYhzajxw54rD8suPHj+vnn3/W8uXLVbNmzcz/JGny5MmZPwMAANwqchxqCg0NVZkyZbR27Vrdddddme3r169X+fLlVapUKYf1Q0JCtGzZsiz76dKlix566CF17tw5H8oGAAAoOHJ1bW/AgAEaPny4/P391apVK23cuFFRUVEaP368JOnMmTOKiYlRpUqV5Ovrq9q1a2e7n5CQkCsuAwAAuFnl6knzkZGReuONN/Tdd99pwIAB2r59u8aMGaOOHTtKkjZt2qRu3brpt99+M1osAABAQZTr2evdu3dX9+7ds10WGRmpyMjIq26/f//+a6sMAADgJpHrl1cDAADg+hC4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYFiuA9eqVat09913Kzw8XBEREVq+fPlV14+Li9Mrr7yi1q1bq27duoqMjFRUVFSeCwYAACho3HOzUlRUlIYMGaJevXqpefPm2rBhg4YOHSovLy916NAhy/opKSnq3bu3EhMT9dxzzykkJETr1q3TCy+8oPT0dN1zzz35fiIAAACuKleBa9y4cYqIiNCIESMkSc2bN1dCQoImTpyYbeDavHmz9u3bp88++0zh4eGSpKZNm+rYsWOaNWsWgQsAANxScrykGBsbq5iYGLVr186hvX379oqOjlZsbGyWbXx8fNStWzfVrl3bob1ChQqKiYnJY8kAAAAFS44jXNHR0ZKksLAwh/bQ0FBJ0uHDh1W2bFmHZY0bN1bjxo0d2lJTU/Xtt9+qcuXKeSoYAACgoMlxhCsxMVGS5Ovr69Du4+MjSUpKSsrVgT744AP9+eef6tu377XWCAAAUKDlOMJlt9slSRaLJdt2q/Xqmc1ut+v999/X3Llz9eSTT6pt27bXXGTRor45rwSnCQ72c3YJKEDoL8gt+gquhav3lxwDl59fxgn8eyTr/PnzDsuzk5KSomHDhmn16tV68skn9dJLL11XkadPJ8lms1/XtvnF1b9IZ4qLS3R2CS6H/nJl9BdH9JUro69kRX+5MlfoL1ar5YqDRDkGrstzt2JiYlS1atXM9iNHjjgs/7ekpCT169dPO3fu1IgRI/Too49ec+EAAAA3gxzncIWGhqpMmTJau3atQ/v69etVvnx5lSpVKss26enp6t+/v37++WeNGzeOsAUAAG5puXoO14ABAzR8+HD5+/urVatW2rhxo6KiojR+/HhJ0pkzZxQTE6NKlSrJ19dXn376qbZv365u3bqpZMmS2r17d+a+LBaL6tSpY+ZsAAAAXFCuAldkZKRSUlI0e/ZsffbZZypbtqzGjBmjjh07SpI2bdqk4cOHa/78+WrYsKHWrVsnSVqyZImWLFnisC83Nzft3bs3n08DAADAdeUqcElS9+7d1b1792yXRUZGKjIyMvP3+fPn570yAACAm0SuX14NAACA60PgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGEELgAAAMMIXAAAAIYRuAAAAAwjcAEAABhG4AIAADCMwAUAAGAYgQsAAMAwAhcAAIBhBC4AAADDCFwAAACGEbgAAAAMI3ABAAAYRuACAAAwjMAFAABgGIELAADAMAIXAACAYQQuAAAAwwhcAAAAhhG4AAAADCNwAQAAGEbgAgAAMIzABQAAYBiBCwAAwDACFwAAgGG5DlyrVq3S3XffrfDwcEVERGj58uVXXf/8+fN644031LRpU9WtW1d9+vTRn3/+mdd6AQAACpxcBa6oqCgNGTJETZs21dSpU3XHHXdo6NChWrt27RW3GThwoNauXashQ4ZozJgxOnHihHr16qXExMR8Kx4AAKAgcM/NSuPGjVNERIRGjBghSWrevLkSEhI0ceJEdejQIcv6O3bs0LfffqtZs2apRYsWkqQGDRrozjvv1OLFi9W3b998PAUAAADXluMIV2xsrGJiYtSuXTuH9vbt2ys6OlqxsbFZttm6dat8fHzUtGnTzLagoCDdfvvt2rx5cz6UDQAAUHDkGLiio6MlSWFhYQ7toaGhkqTDhw9nu01oaKjc3Nwc2suVK5ft+gAAADezHC8pXp5z5evr69Du4+MjSUpKSsqyTVJSUpb1L2+T3fo5sVot17yNCSGB3vmyH3f/4DzvI7hwUD5UInmG5L0WV/l+XE1+9Jf86CtS/vSX/OgrEv0lO/zdkj36Svb4uyV7rtBfrlaDxW6326+28cqVKzVkyBBt3LhRpUuXzmz/888/1b59+2zncT3xxBNKTU3VggULHNrHjx+v+fPna9euXddzHgAAAAVSjpcU/fz8JGUdyTp//rzD8n/y9fXNXP7vbbIb+QIAALiZ5Ri4Ls/diomJcWg/cuSIw/J/bxMbG6t/D54dOXIk2/UBAABuZjkGrtDQUJUpUybLM7fWr1+v8uXLq1SpUlm2adasmc6dO6fvv/8+s+3MmTPasWOHmjRpkg9lAwAAFBxur7/++us5reTn56fp06crPj5eFotFc+bM0ZdffqmRI0eqcuXKOnPmjPbv3y9fX195eHiodOnS2r59uz755BMFBATo2LFjGjFihOx2u0aPHi0vL68bcGoAAACuIcdJ85d9+umnmj17to4fP66yZcuqb9++6tSpkyTpiy++0PDhwzV//nw1bNhQkpSQkKB3331XGzZskM1mU/369TVs2DBVqFDB3NkAAAC4oFwHLgAAAFyfXL+8GgAAANeHwAUAAGAYgQsAAMAwAhcAAIBhBC4Xxz0NAAAUfAQuF9eiRQt98MEHOnTokLNLAQAA14nHQri4Dz74QKtWrdKJEydUq1Ytde7cWXfffXe277AEgOuxf/9+JScny2azZVlWr149J1QEVzBjxoxcr2uxWNSvXz+D1RR8BK4CwG6364cfftCXX36Z+SDZNm3a6IEHHlDz5s1lsVicXSKc5PHHH8/192+xWPTxxx8brggFya+//qrnn39ex44dy7LMbrfLYrHo999/d0JlcAXVqlXL9br0lZwRuAqYCxcuaNOmTVq8eLF27Nih4OBgde7cWQ899JBCQkKcXR5usDFjxmjOnDkqUqSIqlatmuP6CxYsuAFVoaB46KGHdOrUKQ0YMEAlSpSQ1Zp1lskdd9zhhMqAmw+BqwCJi4vTqlWrFBUVpT179qh06dJq2bKlvvvuO508eVLvvPOOOnTo4OwycYMtXLhQ77zzjubMmcM/jrgm4eHhGjdunNq2bevsUoCbHoHLxSUnJ2v9+vVasWKFtm3bpkKFCqldu3bq3Llz5nsr7Xa7evfurf379+u7775zcsVwhsGDB2vfvn1avXq1s0tBAdKqVSuNHDlSrVu3dnYpcEHt2rW7pikr69atM1hNwefu7AJwdU2aNNHFixcVHh6ukSNHqmPHjvL19XVYx2KxqG7dutq/f7+TqoSzpKSkyMPDQy+99JImTJigQ4cOqWLFis4uCwVEjx49NHPmTDVq1Eje3t7OLgcupl69eswRzkeMcLm4MWPGqEuXLjn+I5qUlCQvLy+5u5OhbyXNmjXTlClTdNttt2nKlCnq2rWrihcv7uyyUEC89tprioqKks1mU5UqVbKELm60APIP/zq7uKFDh2rfvn2aO3euHnvsMUkZt3AvWLBAjz/+eGYQ+/eoF24N586d04kTJyRJU6dOVYsWLQhcyLXDhw873ImWmprqxGrg6i5duqQDBw4oNTU186HcNptNycnJ2rFjhwYOHOjkCl0bI1wu7ocfflDfvn1VuXJlffHFF5KkPXv2aMiQITp58qTmzZun8PBwJ1cJZ3nkkUe0a9cuhYSE6NixYwoODpaHh0e261osFm3YsOEGVwjgZrB9+3a98MILio+Pz3a5j4+PduzYcYOrKlgIXC6uW7duKlmypMaOHSs3N7fMdpvNpkGDBun06dPc6n8LO3nypBYsWKCzZ89q2bJlat26tYKCgq64/qhRo25gdSgoDh48qO3btyspKUmBgYGqX7++KlSo4Oyy4EJ69Oih+Ph4DRo0SCtWrJDValVkZKQ2b96sxYsXa9GiRapbt66zy3RpXFJ0cX/88YdeeOEFh7AlSVarVQ8++KCeeeYZJ1UGVxASEqLBgwdLkrZu3arnnnvumh5WiFubzWbTa6+9ps8//9zhva0Wi0WdOnXS6NGjmTQNSdLvv/+uUaNG6a677lJiYqI+/fRTtWzZUi1btlRqaqqmT5+umTNnOrtMl8a7FF2cr6+vYmJisl129OhR7ixCpo0bNxK2cE1mzpyp5cuXa/Dgwfr222/122+/adOmTRo0aJBWrVqljz76yNklwkXYbLbM+aGhoaE6cOBA5rJ27dpp7969ziqtwCBwubh27dppwoQJ2rJli0P7Dz/8oIkTJ/LAQgDXbdmyZXrqqafUu3dvFS9eXG5ubipRooT69Omjfv36admyZc4uES6iXLlymSErLCxMycnJio6OliSlp6fr/PnzziyvQOCSoosbOHCgfv31V/Xp00eenp4KCgpSfHy8Ll26pNq1a+vFF190dokACqi4uDjVr18/22X16tXjEhEy3XPPPXr//fdls9n08MMPq1atWnr77bfVq1cvTZ8+XZUqVXJ2iS6PwOXifH19tXjxYn377bf66aeflJCQIF9fX9WvX19t2rTJ9t1nAJAbZcuW1a5du9S4ceMsy3bt2qXg4GAnVAVX1KdPH505c0Y7d+7Uww8/rJEjR2aOhPr6+mr69OnOLtHlcZciANyi5s6dq3HjxmnQoEHq2PH/27vXoKrKNQ7g/8UGReQyCAFaOCAwattwBKOAFGR22DBCXkKK0iwQNCxAMonIJrUExQq5yaCOowXTMA6a5kAopEQDiQQNNy1EEwabAjZykduG88E5ew4DhodzZK21+/8+bd6XD/9Pe579rGe9rx8sLS3x119/4dtvv8Xnn3+O8PBwREREiB2TJKq7uxs3btzAvHnzeBbkQ2DBJQP5+fm4cuXKuIfN/fzzzyguLhY5IRHJkUajQVxcHM6cOTPqbcSRkREEBAQgISGBXXTSunTpEsrKyrBz504AwC+//KItzJ999lmR00kfHylKXFpaGlJSUmBiYoKhoSEYGBhAX18f7e3t0NPTQ2BgoNgRiUimFAoFEhMTERoaiitXruDu3bswNTWFm5sbZ3JolPPnzyMmJgbLli3Trs2YMQPDw8MICQlBRkYGli9fLmJC6WOHS+JUKhWWLl2Kffv2ITk5Ga2trUhMTERNTQ3CwsLw1ltv4bXXXhM7JhER6bCAgAC4ubkhPj5+zN6ePXtQXV3Nt1onwA6XxN25cwf+/v4QBAFKpRLnz58HACxatAhbtmxBbm4uCy4iemgrV65EcnIyFixYAF9f3wkPNi0oKJiiZCRlv//+O+Li4sbdU6lU2qvn6MFYcEmckZGRdoZi7ty5aG5uRl9fHwwNDbFw4UI0NzeLnJCI5MTFxQUzZ87UfuZJ8vQwLCwsUFtbO+6s1rVr12BmZiZCKnlhwSVxTz31FM6cOQN3d3fY29tDoVCgrKwM3t7eaGpqeuBFxURE49m3b5/2c0JCgohJSE78/f2RmpqKmTNnQqVSwcLCAu3t7SgqKkJKSgqCg4PFjih5nOGSuPLycoSEhGDZsmXIyMjABx98q9ncTwAACrxJREFUgAsXLsDd3R2XLl2CSqXCgQMHxI5JRDLV09ODnp4eWFlZYXBwEF999RVaW1vh6+v7wENR6Z9ncHAQMTEx+O6778a80err64uDBw/CwMBAxITSx4JLBurq6nD9+nWsXr0a/f392Lt3LyorK+Hs7IzY2Fi2coloUqqrq7F582YEBQUhJiYGH330Eb7++muYmpqip6cHKSkp8PHxETsmScj169e1h3CbmJjA1dWVd7g+JBZcEnf8+HF4eXnB3t5e7ChEpGPeeOMN3Lt3DwcOHIClpSXc3d2xdu1a7Nq1C7t27UJ9fT1yc3PFjkkSMzQ0hI6ODpibm0Nfn5NJD4sn2klcWloabt26JXYMItJB1dXV2Lp1K2xtbVFaWor+/n68+OKLAAA/Pz/tZcVEAFBTU4OQkBAsWbIEXl5euHbtGmJjY5GWliZ2NFlgwSVxtra2aGpqEjsGEekgPT09TJ8+HQBQUlICU1NTODs7A7h/bYuhoaGY8UhCKisrERwcDLVajbCwMO2tJzY2NkhNTUV2drbICaWPvUCJU6lUOHjwIL7//ns4OTnB0tJy1L4gCAgPDxcpHRHJ2aJFi5CbmwtDQ0Pk5+fD29sbgiCgra0NWVlZWLRokdgRSSKSkpLg4eGBw4cPY2hoSNvVioqKQl9fH3Jycvim4gQ4wyVxEw0jCoKA+vr6KUpDRLqktrYWoaGh6OjowKxZs5CdnQ07Ozu4u7tjZGQEx44dw5NPPil2TJKAxYsX49ChQ/Dy8oJGo4FSqcSpU6egVCpRXl6O8PBwVFVViR1T0tjhkriGhgaxIxCRjlIqlSgsLERjYyOcnJxgZGQE4P5VLS4uLpg1a5bICUkqZs6ciba2tnH3/vjjD+1huvRgnOEiIvoHMzY2xuLFi7XFFnB/lIHFFv0nHx8ffPHFF6irq9OuCYKAP//8E5mZmfDy8hIxnTzwkaLEvfnmmxP+z7Fjx6YgCRHpAt6lSJOhVqvx+uuv49dff4W1tTVaW1vh6OiIlpYWWFlZIScnh0X6BPhIUeIGBwfHrPX29qKxsRFGRkbw9fUVIRURyRXvUqTJyMzMxIcffogbN26grKwM9vb2MDY2xssvv4y1a9eO6pDS+NjhkqnOzk5s3rwZq1atwsaNG8WOQ0Q6YmRkhEUYjeHq6opDhw7B09NT7CiyxRkumTIzM0NYWBiOHz8udhQikrGcnBxs375d+3dFRQV8fX2Rl5cnYiqSGqVSidLSUrFjyBofKcrcg94aISKayJdffolPPvkEgYGB2jUbGxssXboU8fHx0NPT0548T/9sSqUSJ06cQGFhIRwdHcc9E3L37t0ipZMHPlKUuMrKyjFrw8PDaG1tRUpKCiwtLXnCLxFNysqVKxEQEICIiIgxe6mpqSgoKMDZs2dFSEZSM9El5oIg4OLFi1OURp7Y4ZK44OBgCIIwaq7i3zXy7NmzERcXJ2Y8IpKxO3fuwMXFZdw9V1dXZGVlTXEikqqioiKxI8geCy6JO3HixJg1QRBgbGyM+fPnQ0+PY3hENDlz5sxBeXk53N3dx+xdvXoV1tbWIqQi0k0suCTOzc0NfX19qK2thaurK4D7v0p/+ukn2Nvb83JZIpq0oKAgJCUlQaPRaA877ejoQFFREY4ePYrIyEixIxLpDM5wSdzt27exadMmjIyMaFu6paWlCA0NhaOjI44cOcJfoUQ0aYmJiTh58iQ0Go12TaFQYMOGDdi5c6eIyYh0CwsuiYuIiEBzczOSk5NhZ2enXW9pacG2bdvg4OCApKQk8QISkex1dXWhqqoKarUaJiYmcHZ25qnhRP9nHACSuIqKCkRHR48qtgDg8ccfR0REBH788UdxghGRzjAxMYGDgwNsbW3h5uaGGTNmiB2JSOdwhkviRkZGMDAw8MD9vr6+KUxDRLqmqKgI+/fvx61btyAIAnJzc5Geng4zMzPs2bMHCoVC7IhEOoEdLol7+umnkZ6eDrVaPWr97t27yMzMhJubm0jJiEjuioqKEBERAUdHR+zduxfDw8MAAA8PD3zzzTfIzMwUOSGR7uAMl8Q1NTVh/fr10Gg0cHFxgYWFBdrb21FZWQl9fX1kZ2fDwcFB7JhEJENr1qzBwoUL8emnn0Kj0UCpVOLUqVNQKpXIyMjA6dOnUVBQIHZMIp3ADpfE2dvb49y5cwgKCtIOtra3t2PdunU4ffo0iy0imrTGxkb4+fmNu+fq6orW1tYpTkSkuzjDJQPW1tZ4++23YWRkBADo7u5Gd3c3bGxsRE5GRHJmbm6Omzdv4rnnnhuzd/PmTZibm4uQikg3scMlcb29vYiOjsb69eu1a1VVVVixYgXef//9vx2oJyL6O35+fkhOTsaFCxcwODgI4P5NFg0NDUhPT8cLL7wgckIi3cEZLonbu3cvzp49i/feew/r1q0DAPT09KCwsBCJiYkICgpCVFSUyCmJSI76+/sRERGBH374Afr6+hgaGoKpqSm6urqwZMkSHDlyRNtZJ6L/DQsuiVu+fDmio6OxZs2aMXu5ubnIyMjgpaJE9D8pLS1FWVkZ1Go1jI2N4ebmBm9vbwiCIHY0Ip3BGS6J6+rqgoWFxbh7s2fPRltb2xQnIiJdERUVhVdeeQWenp7w9PQUOw6RTuMMl8TNnz8feXl54+6dOXMGTk5OU5yIiHRFSUkJ+JCDaGqwwyVxW7duxZYtW9DS0gKVSqU9h6u4uBhVVVVIT08XOyIRyZSHhwfy8vLg4uKCadOmiR2HSKdxhksGiouLkZKSgvr6eu2v0QULFuCdd96Bj4+PyOmISK5iY2Nx7tw5GBgYwNbWFpaWlqP2BUHA0aNHRUpHpFtYcMlER0cHBgYGoNFooFAoMDIygt7eXly9ehWBgYFixyMiGdqwYcOE/3Py5MkpSEKk+1hwSdy1a9fw7rvv4rfffht3XxAE1NXVTXEqItIljY2NqKioQGdnJywsLPDMM8/giSeeEDsWkU7hDJfE7d+/H2q1Gjt37kRxcTGmTZuGFStW4PLly7h06RJOnDghdkQikqn+/n7s2LEDhYWFo4bn9fT08NJLL+Hjjz/m0RBE/yd8S1HiqqqqEBkZiU2bNsHPzw/37t1DcHAwDh8+jOeff57tfiKatISEBJSUlCA+Ph4lJSWora3F5cuXERsbi7NnzyItLU3siEQ6gwWXxA0MDMDOzg4AYGdnh4aGBu3e2rVrUVVVJVIyIpK7/Px8bN++Ha+++ioee+wxKBQKWFlZYePGjYiMjERubq7YEYl0BgsuiZszZw6am5sB3C+4uru70dLSAgCYPn06Ojs7xYxHRDI2ODgIW1vbcfccHBzQ1dU1xYmIdBcLLolTqVRISkpCYWEhrK2tMW/ePCQnJ6OxsRHHjx9/4JclEdFEVq9ejaysLPT19Y1aHx4eRk5ODlatWiVSMiLdw7cUJe7evXvYsWMH+vv7kZWVhZKSEmzbtg0DAwNQKBT47LPP4OvrK3ZMIpKhlJQUnDx5Evr6+vDx8YGVlRXUajVKSkrQ0tICf39/7YGogiBg9+7dIicmki8WXDIxMDCg/eK7ffs2ampqoFQqMXfuXJGTEZFc/TcHJwuCgIsXLz7CNES6jQUXERER0SPGGS4iIiKiR4wFFxEREdEjxoKLiIiI6BFjwUVERET0iLHgIiIiInrE/gVSaXZQ32yYCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_metrics=pd.DataFrame({\"baseline\":baseline_metrics,\n",
    "                              \"clf_2\": clf_2_metrics,\n",
    "                              \"random search\": rs_metrics,\n",
    "                              \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10,8));\n",
    "\n",
    "# select which u want based on what metrics u want to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the first model(baseline) is most likely the best model.. u can improve upon it\n",
    "\n",
    "# correlation analysis-- forward/backward attribute selection is a way to improve our model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SAVING AND LOADING TRAINED MACHINE LEARNING MODELS\n",
    "\n",
    "there are two ways to save and load ML models\"\n",
    "\n",
    "    **** with python's pickle module\n",
    "    **** with the joblib module\n",
    "    \n",
    "    \n",
    "**Pickle**\n",
    "\n",
    "for python object serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# python object is the model\n",
    "\n",
    "# save an existing model to file\n",
    "# pickle.dump(gs_clf,open(\"gs_random_forest_model_1.pkl\", \"wb\")) #wb is write binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a saved model\n",
    "\n",
    "loaded_pickle_model = pickle.load(open(\"gs_random_forest_model_1.pkl\", \"rb\")) #rb is read binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:78.69%\n",
      "Precision: 0.74\n",
      "Recall:0.82\n",
      "F1 score:0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79, 'precision': 0.74, 'recall': 0.82, 'f1': 0.78}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make  some predictions\n",
    "pickle_y_preds = loaded_pickle_model.predict(X_test) # if u get a size error, reinstantiate X\n",
    "evaluate_preds(y_test, pickle_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joblib\n",
    "\n",
    "running python functions as pipeline jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump,load\n",
    "\n",
    "# to save model to file\n",
    "# dump(gs_clf, filename=\"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a saved joblib model\n",
    "loaded_joblib_model=load(filename=\"gs_random_forest_model_1.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:78.69%\n",
      "Precision: 0.74\n",
      "Recall:0.82\n",
      "F1 score:0.78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79, 'precision': 0.74, 'recall': 0.82, 'f1': 0.78}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make and evaluate joblib predictions\n",
    "joblib_y_preds=loaded_joblib_model.predict(X_test)\n",
    "evaluate_preds(y_test, joblib_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit learn saving a model ----model persistence---\n",
    "# python built in persistence model--pickle\n",
    "\n",
    "# specific case of sci-kit learn, use joblib replacement of pickle is more efficient for models that carry large np arrays internally\n",
    "# for fitted sklarn estimator(e.g. gs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. PUTTING IT ALL TOGETHER using the pipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn pipeline- pipeline of transforms with a final estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Red</td>\n",
       "      <td>42652.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23883.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163453.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20306.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>130538.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>51029.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>167421.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Green</td>\n",
       "      <td>17119.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>102303.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>134181.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>199833.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>205592.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>96742.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BMW</td>\n",
       "      <td>White</td>\n",
       "      <td>194189.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>White</td>\n",
       "      <td>67991.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>215820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124844.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Honda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30615.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29653.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>148744.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>130075.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>172718.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>125819.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>180390.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>82783.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10984.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>56687.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>112004.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13586.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>186309.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Black</td>\n",
       "      <td>178164.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>237627.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155383.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Honda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22409.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>95317.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>128016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>BMW</td>\n",
       "      <td>White</td>\n",
       "      <td>85739.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>17975.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>230314.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>129454.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>238172.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>157235.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Blue</td>\n",
       "      <td>216250.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9691.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>71934.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26882.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215235.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Black</td>\n",
       "      <td>248736.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>41735.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>173408.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8082.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Blue</td>\n",
       "      <td>235985.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Honda</td>\n",
       "      <td>Green</td>\n",
       "      <td>54721.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>27419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Black</td>\n",
       "      <td>162523.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4696.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>163322.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "5     Honda    Red        42652.0    4.0  23883.0\n",
       "6    Toyota   Blue       163453.0    4.0   8473.0\n",
       "7     Honda  White            NaN    4.0  20306.0\n",
       "8       NaN  White       130538.0    4.0   9374.0\n",
       "9     Honda   Blue        51029.0    4.0  26683.0\n",
       "10   Nissan  White       167421.0    4.0  16259.0\n",
       "11   Nissan  Green        17119.0    4.0   6160.0\n",
       "12   Nissan  White       102303.0    4.0  16909.0\n",
       "13      NaN  White       134181.0    4.0  11121.0\n",
       "14    Honda   Blue       199833.0    4.0  18946.0\n",
       "15   Toyota   Blue       205592.0    4.0  16290.0\n",
       "16   Toyota    Red        96742.0    4.0  34465.0\n",
       "17      BMW  White       194189.0    5.0  17177.0\n",
       "18   Nissan  White        67991.0    3.0   9109.0\n",
       "19   Nissan   Blue       215820.0    4.0   6010.0\n",
       "20   Toyota    NaN       124844.0    4.0  24130.0\n",
       "21    Honda    NaN        30615.0    4.0  29653.0\n",
       "22   Toyota  White       148744.0    4.0  22489.0\n",
       "23    Honda  Green       130075.0    4.0  21242.0\n",
       "24    Honda   Blue       172718.0    4.0  14274.0\n",
       "25    Honda   Blue       125819.0    4.0  15686.0\n",
       "26    Honda  White       180390.0    4.0  13344.0\n",
       "27    Honda  Green        82783.0    4.0  10984.0\n",
       "28    Honda  White        56687.0    4.0   6135.0\n",
       "29   Toyota  White       112004.0    4.0  13586.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "970  Toyota   Blue       186309.0    4.0  16416.0\n",
       "971     BMW  Black       178164.0    3.0  24891.0\n",
       "972   Honda  White            NaN    4.0  17939.0\n",
       "973   Honda  Green       237627.0    4.0   8430.0\n",
       "974     NaN  White       155383.0    4.0  14345.0\n",
       "975   Honda    NaN        22409.0    4.0  10429.0\n",
       "976  Toyota   Blue        95317.0    4.0   7435.0\n",
       "977  Toyota   Blue       128016.0    4.0  16835.0\n",
       "978     BMW  White        85739.0    5.0  48419.0\n",
       "979  Toyota  Black        17975.0    4.0  17940.0\n",
       "980  Toyota   Blue       230314.0    4.0   6720.0\n",
       "981  Toyota  White       129454.0    4.0   6446.0\n",
       "982   Honda  White       238172.0    4.0  13273.0\n",
       "983  Toyota    Red            NaN    4.0  14671.0\n",
       "984  Nissan   Blue       157235.0    4.0   4196.0\n",
       "985     NaN   Blue       216250.0    4.0   9691.0\n",
       "986   Honda  White        71934.0    4.0  26882.0\n",
       "987   Honda  White       215235.0    4.0   3825.0\n",
       "988  Nissan  Black       248736.0    4.0   8358.0\n",
       "989  Toyota    Red        41735.0    4.0  13928.0\n",
       "990  Toyota  White       173408.0    4.0   8082.0\n",
       "991   Honda   Blue       235985.0    4.0   9184.0\n",
       "992   Honda  Green        54721.0    4.0  27419.0\n",
       "993  Nissan  Black       162523.0    4.0   4696.0\n",
       "994     BMW   Blue       163322.0    3.0  31666.0\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"csv_files/car-sales-extended-missing-data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sure data is numerical and no missing values\n",
    "\n",
    "Steps we want to do(all in one cell):\n",
    "    1. fill missing data\n",
    "    2 convert data to numbers\n",
    "    3. build a model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isaac Alexander\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1821575815702311"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting data ready\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer # to fill missing data\n",
    "from sklearn.preprocessing import OneHotEncoder # convert to number\n",
    " \n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor #predict price of car a regression prob\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # optimum hyperparams for regressor\n",
    "\n",
    "# Setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# import data and drop rows with missing labels\n",
    "data= pd.read_csv(\"csv_files/car-sales-extended-missing-data.csv\")\n",
    "data.dropna(subset=[\"Price\"], inplace=True)\n",
    "\n",
    "# define diff features and transformer pipeline\n",
    "categorical_features=[\"Make\", \"Colour\"]\n",
    "#modifying the data\n",
    "#pipelibe(steps= a list of tuples [(name_of_action, action_to_take)])\n",
    "categorical_transformer=Pipeline(steps=[\n",
    "                                        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),#categorical features should have a constant value of missing\n",
    "                                        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))# ignore columns not defined\n",
    "                                       ]\n",
    "                                ) \n",
    "door_feature=[\"Doors\"]\n",
    "door_transformer=Pipeline(steps=[\n",
    "                                (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=4)),\n",
    "                                ]\n",
    "                         )\n",
    "numeric_features=[\"Odometer (KM)\"]\n",
    "numeric_transformer=Pipeline(steps=[\n",
    "                                    (\"imputer\", SimpleImputer(strategy=\"mean\"))\n",
    "                                    ]\n",
    "                            )\n",
    "\n",
    "#setup preprocessing steps(fill missing values, then convert to numbers)\n",
    "preprocessor=ColumnTransformer(\n",
    "                 transformers=[\n",
    "                     (\"cat\", categorical_transformer, categorical_features),\n",
    "                     (\"door\", door_transformer, door_feature),\n",
    "                     (\"num\", numeric_transformer, numeric_features)\n",
    "                              ]\n",
    "                              )\n",
    "\n",
    "# creating a preprocessing and modelling pipeline\n",
    "model=Pipeline(steps=[(\"preprocessor\", preprocessor),\n",
    "                       (\"model\", RandomForestRegressor())\n",
    "                      ]\n",
    "               )\n",
    "# split data\n",
    "X=data.drop(\"Price\", axis=1)\n",
    "y=data[\"Price\"]\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "#fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#improving this using hyperparameters tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it is possible to use GridSearchCv or RandomizedSearchCv with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.7s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   5.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   5.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.9s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.9s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.9s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.8s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   5.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   4.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   4.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.4s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.3s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.9s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.9s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   2.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value='missing',\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy=...\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': ['auto'],\n",
       "                         'model__min_samples_split': [2, 4],\n",
       "                         'model__n_estimators': [100, 1000],\n",
       "                         'preprocessor__num__imputer__strategy': ['mean',\n",
       "                                                                  'median']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use GridSearchCV with regression pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_grid={\n",
    "           \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"], #__ shows the level u go\n",
    "           \"model__n_estimators\":[100,1000],\n",
    "           \"model__max_depth\":[None,5],\n",
    "           \"model__max_features\": [\"auto\"],\n",
    "           \"model__min_samples_split\":[2,4]\n",
    "          }\n",
    "\n",
    "gs_model=GridSearchCV(model,pipe_grid,cv=5, verbose=2) #verbose prints out the level of progress so we would see\n",
    "gs_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3337859800130589"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gs_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
